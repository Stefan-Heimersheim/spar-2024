{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b856f2-3540-4d72-be0b-5d9eb1cf86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import torch as t\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd1dd5-33fb-4eaf-b11a-b320d2f7ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def load_tensors_into_dict(directory):\n",
    "    # Dictionary to store the loaded tensors\n",
    "    tensor_dict = {}\n",
    "    \n",
    "    # Pattern to match the filenames\n",
    "    pattern = r'layer_(\\d+)__feat_(\\d+)__num_batches_\\d+__batch_size_\\d+\\.pth'\n",
    "    \n",
    "    # Find all .pth files in the directory\n",
    "    for filepath in glob.glob(os.path.join(directory, '*.pth')):\n",
    "        # Extract layer_idx and feat_idx from the filename\n",
    "        match = re.search(pattern, os.path.basename(filepath))\n",
    "        if match:\n",
    "            layer_idx, feat_idx = match.groups()\n",
    "            \n",
    "            # Create the key\n",
    "            key = f'layer_{layer_idx}_feat_{feat_idx}'\n",
    "            \n",
    "            # Load the tensor\n",
    "            tensor = t.load(filepath)\n",
    "            \n",
    "            # Add to the dictionary\n",
    "            tensor_dict[key] = tensor\n",
    "    \n",
    "    return tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8192fa-ae45-4d86-95d8-d1b405a2ff11",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m/data/ben_lerner/spar-2024/playground/ben/analyze_ablations.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      2\u001b[0m directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39martefacts/ablations\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m result \u001b[39m=\u001b[39m load_tensors_into_dict(directory)\n",
      "File \u001b[1;32m/data/ben_lerner/spar-2024/playground/ben/analyze_ablations.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m key \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlayer_\u001b[39m\u001b[39m{\u001b[39;00mlayer_idx\u001b[39m}\u001b[39;00m\u001b[39m_feat_\u001b[39m\u001b[39m{\u001b[39;00mfeat_idx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[39m# Load the tensor\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m tensor \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mload(filepath)\n\u001b[1;32m     22\u001b[0m \u001b[39m# Add to the dictionary\u001b[39;00m\n\u001b[1;32m     23\u001b[0m tensor_dict[key] \u001b[39m=\u001b[39m tensor\n",
      "File \u001b[0;32m~/miniconda3/envs/spar/lib/python3.11/site-packages/torch/serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1024\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[1;32m   1026\u001b[0m                      map_location,\n\u001b[1;32m   1027\u001b[0m                      pickle_module,\n\u001b[1;32m   1028\u001b[0m                      overall_storage\u001b[39m=\u001b[39;49moverall_storage,\n\u001b[1;32m   1029\u001b[0m                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m   1030\u001b[0m \u001b[39mif\u001b[39;00m mmap:\n\u001b[1;32m   1031\u001b[0m     f_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(f, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/spar/lib/python3.11/site-packages/torch/serialization.py:1446\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1444\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1445\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1446\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1448\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1449\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1450\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtorch.load.metadata\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mserialization_id\u001b[39m\u001b[39m\"\u001b[39m: zip_file\u001b[39m.\u001b[39mserialization_id()}\n\u001b[1;32m   1451\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/spar/lib/python3.11/site-packages/torch/serialization.py:1416\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1415\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1416\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1418\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/spar/lib/python3.11/site-packages/torch/serialization.py:1390\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1385\u001b[0m         storage\u001b[39m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1387\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1388\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1389\u001b[0m typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1390\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1391\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m   1392\u001b[0m     _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1394\u001b[0m \u001b[39mif\u001b[39;00m typed_storage\u001b[39m.\u001b[39m_data_ptr() \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1395\u001b[0m     loaded_storages[key] \u001b[39m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/spar/lib/python3.11/site-packages/torch/serialization.py:390\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    389\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 390\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    391\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/spar/lib/python3.11/site-packages/torch/serialization.py:265\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 265\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    266\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    267\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/miniconda3/envs/spar/lib/python3.11/site-packages/torch/serialization.py:249\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    246\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    248\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    250\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    251\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    252\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    253\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    254\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    255\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "directory = 'artefacts/ablations'\n",
    "result = load_tensors_into_dict(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55f8ae-9f00-4f69-9126-e2e5d38c0892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded device='cpu'\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "import torch as t\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "if t.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    "print(f\"Loaded {device=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a4085a-6784-47db-8d02-efdc216bef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def load_tensors_into_dict(directory):\n",
    "    # Dictionary to store the loaded tensors\n",
    "    tensor_dict = {}\n",
    "    \n",
    "    # Pattern to match the filenames\n",
    "    pattern = r'layer_(\\d+)__feat_(\\d+)__num_batches_\\d+__batch_size_\\d+\\.pth'\n",
    "    \n",
    "    # Find all .pth files in the directory\n",
    "    for filepath in glob.glob(os.path.join(directory, '*.pth')):\n",
    "        # Extract layer_idx and feat_idx from the filename\n",
    "        match = re.search(pattern, os.path.basename(filepath))\n",
    "        if match:\n",
    "            layer_idx, feat_idx = match.groups()\n",
    "            \n",
    "            # Create the key\n",
    "            key = f'layer_{layer_idx}_feat_{feat_idx}'\n",
    "            \n",
    "            # Load the tensor\n",
    "            tensor = t.load(filepath, map_location=t.device(device))\n",
    "            \n",
    "            # Add to the dictionary\n",
    "            tensor_dict[key] = tensor\n",
    "    \n",
    "    return tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ae039-8929-449f-a64e-cd298e74a8e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m/data/ben_lerner/spar-2024/playground/ben/analyze_ablations.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      2\u001b[0m directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39martefacts/ablations\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m result \u001b[39m=\u001b[39m load_tensors_into_dict(directory)\n",
      "File \u001b[1;32m/data/ben_lerner/spar-2024/playground/ben/analyze_ablations.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m key \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlayer_\u001b[39m\u001b[39m{\u001b[39;00mlayer_idx\u001b[39m}\u001b[39;00m\u001b[39m_feat_\u001b[39m\u001b[39m{\u001b[39;00mfeat_idx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[39m# Load the tensor\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m tensor \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mload(filepath, map_location\u001b[39m=\u001b[39;49mt\u001b[39m.\u001b[39;49mdevice(device))\n\u001b[1;32m     22\u001b[0m \u001b[39m# Add to the dictionary\u001b[39;00m\n\u001b[1;32m     23\u001b[0m tensor_dict[key] \u001b[39m=\u001b[39m tensor\n",
      "File \u001b[0;32m~/miniconda3/envs/spar/lib/python3.11/site-packages/torch/serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1024\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[1;32m   1026\u001b[0m                      map_location,\n\u001b[1;32m   1027\u001b[0m                      pickle_module,\n\u001b[1;32m   1028\u001b[0m                      overall_storage\u001b[39m=\u001b[39;49moverall_storage,\n\u001b[1;32m   1029\u001b[0m                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m   1030\u001b[0m \u001b[39mif\u001b[39;00m mmap:\n\u001b[1;32m   1031\u001b[0m     f_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(f, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/spar/lib/python3.11/site-packages/torch/serialization.py:1446\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1444\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1445\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1446\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1448\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1449\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1450\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtorch.load.metadata\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mserialization_id\u001b[39m\u001b[39m\"\u001b[39m: zip_file\u001b[39m.\u001b[39mserialization_id()}\n\u001b[1;32m   1451\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/spar/lib/python3.11/site-packages/torch/serialization.py:1416\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1415\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1416\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1418\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/spar/lib/python3.11/site-packages/torch/serialization.py:1381\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     storage \u001b[39m=\u001b[39m overall_storage[storage_offset:storage_offset \u001b[39m+\u001b[39m numel]\n\u001b[1;32m   1380\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1381\u001b[0m     storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39;49mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39;49mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n\u001b[1;32m   1382\u001b[0m \u001b[39m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[1;32m   1383\u001b[0m \u001b[39mif\u001b[39;00m byteorderdata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "directory = 'artefacts/ablations'\n",
    "result = load_tensors_into_dict(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8642c2-f463-4875-91bd-b4d5e171a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def load_tensors_into_dict(directory):\n",
    "    # Dictionary to store the loaded tensors\n",
    "    tensor_dict = {}\n",
    "    \n",
    "    # Pattern to match the filenames\n",
    "    pattern = r'layer_(\\d+)__feat_(\\d+)__num_batches_\\d+__batch_size_\\d+\\.pth'\n",
    "    \n",
    "    # Find all .pth files in the directory\n",
    "    for filepath in glob.glob(os.path.join(directory, '*.pth')):\n",
    "        # Extract layer_idx and feat_idx from the filename\n",
    "        match = re.search(pattern, os.path.basename(filepath))\n",
    "        if match:\n",
    "            layer_idx, feat_idx = match.groups()\n",
    "            \n",
    "            # Create the key\n",
    "            key = f'layer_{layer_idx}_feat_{feat_idx}'\n",
    "            \n",
    "            # Load the tensor\n",
    "            tensor = t.load(filepath, map_location=t.device(device))\n",
    "            \n",
    "            # Add to the dictionary\n",
    "            tensor_dict[key] = tensor\n",
    "        # TODO: remove\n",
    "        break\n",
    "    \n",
    "    return tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e9746e-536d-4273-bce4-915666721fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "directory = 'artefacts/ablations'\n",
    "result = load_tensors_into_dict(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_0_feat_4580': {'sae_errors': tensor([[[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "             3.3407e-04,  1.0646e-03],\n",
       "           [-5.1186e-03,  1.8308e-02,  5.6459e-03,  ..., -2.9386e-03,\n",
       "             5.5855e-03,  4.7449e-03],\n",
       "           [ 1.3691e-03, -3.9159e-03, -2.5745e-04,  ...,  1.3716e-03,\n",
       "             1.3642e-03,  1.4481e-03],\n",
       "           ...,\n",
       "           [ 2.6384e-04, -1.4210e-03,  4.6958e-03,  ...,  2.7325e-03,\n",
       "             2.6579e-04,  3.6625e-03],\n",
       "           [ 9.2445e-04,  3.0203e-03,  4.8355e-03,  ...,  1.2169e-04,\n",
       "             1.1595e-03, -1.1107e-03],\n",
       "           [-5.7736e-02, -1.0445e-01,  6.6852e-03,  ..., -2.1304e-02,\n",
       "            -7.3209e-02, -4.2357e-02]],\n",
       "  \n",
       "          [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "             3.3407e-04,  1.0646e-03],\n",
       "           [ 1.6750e-03, -2.3648e-03,  1.4567e-03,  ...,  4.4935e-03,\n",
       "             4.8193e-03, -1.1140e-03],\n",
       "           [ 1.9542e-03, -2.1624e-03,  1.0924e-02,  ..., -4.6064e-04,\n",
       "            -9.1030e-04,  1.9664e-03],\n",
       "           ...,\n",
       "           [-7.2949e-04, -1.8254e-03,  1.2728e-02,  ...,  3.5381e-03,\n",
       "             4.6094e-03,  6.9130e-03],\n",
       "           [ 3.4838e-03,  3.3630e-03,  7.3133e-03,  ...,  2.0694e-03,\n",
       "             4.8414e-03, -1.3369e-03],\n",
       "           [ 2.4466e-02,  1.5942e-02, -1.1117e-02,  ...,  4.7267e-02,\n",
       "            -7.5200e-02,  3.6721e-02]],\n",
       "  \n",
       "          [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "             3.3407e-04,  1.0646e-03],\n",
       "           [-8.5151e-04, -2.3837e-03,  7.6306e-03,  ...,  1.4611e-03,\n",
       "            -8.7495e-04,  1.6211e-03],\n",
       "           [-6.9034e-04, -8.5071e-04, -3.8391e-03,  ...,  3.0022e-04,\n",
       "             4.7869e-03,  1.6768e-04],\n",
       "           ...,\n",
       "           [ 1.5571e-02, -4.1898e-02, -7.9068e-02,  ...,  1.5739e-01,\n",
       "            -7.3942e-02,  1.3117e-01],\n",
       "           [ 2.7662e-03, -1.8523e-03,  1.1043e-02,  ..., -3.2129e-03,\n",
       "            -4.9564e-04, -8.6992e-03],\n",
       "           [ 5.2259e-02, -8.6767e-02,  2.6227e-03,  ...,  3.0250e-03,\n",
       "             3.8609e-02,  4.7577e-02]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "             3.3407e-04,  1.0646e-03],\n",
       "           [ 6.1225e-03, -1.9842e-03, -1.2246e-04,  ...,  8.7433e-05,\n",
       "             2.5042e-03,  3.1428e-03],\n",
       "           [-4.9873e-04, -4.5580e-04,  3.5401e-03,  ...,  7.4563e-04,\n",
       "             3.0457e-03, -1.0869e-03],\n",
       "           ...,\n",
       "           [-5.6946e-04,  2.4207e-03,  1.1234e-02,  ...,  1.2232e-02,\n",
       "             1.3113e-03,  2.1727e-04],\n",
       "           [-6.0867e-03,  2.6940e-03,  1.2050e-02,  ..., -8.7109e-03,\n",
       "             7.4895e-03,  1.0219e-02],\n",
       "           [-7.8616e-04, -6.3965e-03,  1.0159e-02,  ...,  6.9328e-03,\n",
       "             1.0533e-04,  6.4381e-03]],\n",
       "  \n",
       "          [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "             3.3407e-04,  1.0646e-03],\n",
       "           [-7.1019e-04, -7.6427e-04, -9.5546e-05,  ...,  7.3489e-03,\n",
       "            -5.0640e-04,  5.5953e-03],\n",
       "           [ 6.2035e-04, -4.5643e-03,  1.8236e-03,  ...,  1.8036e-03,\n",
       "             1.8542e-03,  9.1480e-04],\n",
       "           ...,\n",
       "           [-8.0941e-04, -3.5270e-03,  8.3167e-03,  ...,  3.9547e-03,\n",
       "             3.7081e-03,  3.9895e-03],\n",
       "           [ 1.1322e-03,  1.9975e-03,  5.7750e-03,  ..., -1.0320e-03,\n",
       "             2.3754e-03, -3.5826e-04],\n",
       "           [-3.1919e-03, -3.9398e-03,  8.8295e-03,  ...,  3.8699e-03,\n",
       "             2.6743e-03,  5.2993e-03]],\n",
       "  \n",
       "          [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "             3.3407e-04,  1.0646e-03],\n",
       "           [-9.7657e-04, -1.5185e-03, -6.8726e-03,  ...,  2.4818e-03,\n",
       "             2.2567e-03,  1.7896e-03],\n",
       "           [-6.9454e-04, -2.3849e-03,  5.4411e-04,  ...,  4.0318e-03,\n",
       "             8.4965e-04,  3.2813e-03],\n",
       "           ...,\n",
       "           [ 3.1123e-04, -9.2459e-03,  1.1593e-02,  ...,  3.9177e-04,\n",
       "             1.5834e-03,  6.1996e-03],\n",
       "           [-4.0504e-03, -3.3954e-03,  4.3334e-03,  ..., -3.0627e-03,\n",
       "             7.0965e-03, -1.8539e-03],\n",
       "           [-4.1930e-03, -3.7756e-03,  6.1542e-03,  ...,  2.7565e-03,\n",
       "             1.7967e-03,  8.5162e-03]]]),\n",
       "  'second_layer_unablated_acts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       "  'second_layer_ablated_acts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       "  'sum_of_f2_diffs': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       "  'sum_of_squared_f2_diffs': tensor([2.4058e-10, 6.1355e-10, 4.5209e-09,  ..., 2.8490e-10, 7.5632e-10,\n",
       "          7.5371e-10]),\n",
       "  'sum_of_squared_masked_f2_diffs': tensor([2.4058e-10, 6.1355e-10, 4.5209e-09,  ..., 2.8490e-10, 7.5632e-10,\n",
       "          7.5371e-10]),\n",
       "  'masked_n': tensor([ 42.,  55., 197.,  ...,  15.,  39.,  99.]),\n",
       "  'mean_diffs': tensor([ 3.8312e-11, -1.1198e-10,  3.3833e-10,  ..., -4.2860e-11,\n",
       "           1.5496e-10,  9.6747e-11]),\n",
       "  'm2_diffs': tensor([2.4058e-10, 6.1354e-10, 4.5208e-09,  ..., 2.8490e-10, 7.5632e-10,\n",
       "          7.5371e-10]),\n",
       "  'sum_unablated_f2': tensor([100.6066, 612.8319, 300.3090,  ..., 129.9649, 525.6078, 156.1537]),\n",
       "  'sum_ablated_f2': tensor([100.6065, 612.8320, 300.3090,  ..., 129.9649, 525.6078, 156.1537]),\n",
       "  'masked_means': tensor([ 2.3913e-07, -5.3373e-07,         nan,  ...,         nan,\n",
       "                  nan,         nan]),\n",
       "  'masked_m2': tensor([1.3065e-07, 1.1446e-06,        nan,  ...,        nan,        nan,\n",
       "                 nan]),\n",
       "  'mse': tensor([9.1774e-16, 2.3405e-15, 1.7246e-14,  ..., 1.0868e-15, 2.8851e-15,\n",
       "          2.8752e-15]),\n",
       "  'masked_mse': tensor([5.7281e-12, 1.1155e-11, 2.2949e-11,  ..., 1.8993e-11, 1.9393e-11,\n",
       "          7.6132e-12]),\n",
       "  'variances': tensor([9.1774e-16, 2.3405e-15, 1.7246e-14,  ..., 1.0868e-15, 2.8851e-15,\n",
       "          2.8752e-15]),\n",
       "  'std_devs': tensor([3.0294e-08, 4.8379e-08, 1.3132e-07,  ..., 3.2967e-08, 5.3713e-08,\n",
       "          5.3621e-08]),\n",
       "  'masked_variances': tensor([3.1108e-09, 2.0812e-08,        nan,  ...,        nan,        nan,\n",
       "                 nan]),\n",
       "  'masked_stdevs': tensor([3.0294e-08, 4.8379e-08, 1.3132e-07,  ..., 3.2967e-08, 5.3713e-08,\n",
       "          5.3621e-08])}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dict.keys>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['layer_0_feat_4580'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sae_errors': tensor([[[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "            3.3407e-04,  1.0646e-03],\n",
       "          [-5.1186e-03,  1.8308e-02,  5.6459e-03,  ..., -2.9386e-03,\n",
       "            5.5855e-03,  4.7449e-03],\n",
       "          [ 1.3691e-03, -3.9159e-03, -2.5745e-04,  ...,  1.3716e-03,\n",
       "            1.3642e-03,  1.4481e-03],\n",
       "          ...,\n",
       "          [ 2.6384e-04, -1.4210e-03,  4.6958e-03,  ...,  2.7325e-03,\n",
       "            2.6579e-04,  3.6625e-03],\n",
       "          [ 9.2445e-04,  3.0203e-03,  4.8355e-03,  ...,  1.2169e-04,\n",
       "            1.1595e-03, -1.1107e-03],\n",
       "          [-5.7736e-02, -1.0445e-01,  6.6852e-03,  ..., -2.1304e-02,\n",
       "           -7.3209e-02, -4.2357e-02]],\n",
       " \n",
       "         [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "            3.3407e-04,  1.0646e-03],\n",
       "          [ 1.6750e-03, -2.3648e-03,  1.4567e-03,  ...,  4.4935e-03,\n",
       "            4.8193e-03, -1.1140e-03],\n",
       "          [ 1.9542e-03, -2.1624e-03,  1.0924e-02,  ..., -4.6064e-04,\n",
       "           -9.1030e-04,  1.9664e-03],\n",
       "          ...,\n",
       "          [-7.2949e-04, -1.8254e-03,  1.2728e-02,  ...,  3.5381e-03,\n",
       "            4.6094e-03,  6.9130e-03],\n",
       "          [ 3.4838e-03,  3.3630e-03,  7.3133e-03,  ...,  2.0694e-03,\n",
       "            4.8414e-03, -1.3369e-03],\n",
       "          [ 2.4466e-02,  1.5942e-02, -1.1117e-02,  ...,  4.7267e-02,\n",
       "           -7.5200e-02,  3.6721e-02]],\n",
       " \n",
       "         [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "            3.3407e-04,  1.0646e-03],\n",
       "          [-8.5151e-04, -2.3837e-03,  7.6306e-03,  ...,  1.4611e-03,\n",
       "           -8.7495e-04,  1.6211e-03],\n",
       "          [-6.9034e-04, -8.5071e-04, -3.8391e-03,  ...,  3.0022e-04,\n",
       "            4.7869e-03,  1.6768e-04],\n",
       "          ...,\n",
       "          [ 1.5571e-02, -4.1898e-02, -7.9068e-02,  ...,  1.5739e-01,\n",
       "           -7.3942e-02,  1.3117e-01],\n",
       "          [ 2.7662e-03, -1.8523e-03,  1.1043e-02,  ..., -3.2129e-03,\n",
       "           -4.9564e-04, -8.6992e-03],\n",
       "          [ 5.2259e-02, -8.6767e-02,  2.6227e-03,  ...,  3.0250e-03,\n",
       "            3.8609e-02,  4.7577e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "            3.3407e-04,  1.0646e-03],\n",
       "          [ 6.1225e-03, -1.9842e-03, -1.2246e-04,  ...,  8.7433e-05,\n",
       "            2.5042e-03,  3.1428e-03],\n",
       "          [-4.9873e-04, -4.5580e-04,  3.5401e-03,  ...,  7.4563e-04,\n",
       "            3.0457e-03, -1.0869e-03],\n",
       "          ...,\n",
       "          [-5.6946e-04,  2.4207e-03,  1.1234e-02,  ...,  1.2232e-02,\n",
       "            1.3113e-03,  2.1727e-04],\n",
       "          [-6.0867e-03,  2.6940e-03,  1.2050e-02,  ..., -8.7109e-03,\n",
       "            7.4895e-03,  1.0219e-02],\n",
       "          [-7.8616e-04, -6.3965e-03,  1.0159e-02,  ...,  6.9328e-03,\n",
       "            1.0533e-04,  6.4381e-03]],\n",
       " \n",
       "         [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "            3.3407e-04,  1.0646e-03],\n",
       "          [-7.1019e-04, -7.6427e-04, -9.5546e-05,  ...,  7.3489e-03,\n",
       "           -5.0640e-04,  5.5953e-03],\n",
       "          [ 6.2035e-04, -4.5643e-03,  1.8236e-03,  ...,  1.8036e-03,\n",
       "            1.8542e-03,  9.1480e-04],\n",
       "          ...,\n",
       "          [-8.0941e-04, -3.5270e-03,  8.3167e-03,  ...,  3.9547e-03,\n",
       "            3.7081e-03,  3.9895e-03],\n",
       "          [ 1.1322e-03,  1.9975e-03,  5.7750e-03,  ..., -1.0320e-03,\n",
       "            2.3754e-03, -3.5826e-04],\n",
       "          [-3.1919e-03, -3.9398e-03,  8.8295e-03,  ...,  3.8699e-03,\n",
       "            2.6743e-03,  5.2993e-03]],\n",
       " \n",
       "         [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "            3.3407e-04,  1.0646e-03],\n",
       "          [-9.7657e-04, -1.5185e-03, -6.8726e-03,  ...,  2.4818e-03,\n",
       "            2.2567e-03,  1.7896e-03],\n",
       "          [-6.9454e-04, -2.3849e-03,  5.4411e-04,  ...,  4.0318e-03,\n",
       "            8.4965e-04,  3.2813e-03],\n",
       "          ...,\n",
       "          [ 3.1123e-04, -9.2459e-03,  1.1593e-02,  ...,  3.9177e-04,\n",
       "            1.5834e-03,  6.1996e-03],\n",
       "          [-4.0504e-03, -3.3954e-03,  4.3334e-03,  ..., -3.0627e-03,\n",
       "            7.0965e-03, -1.8539e-03],\n",
       "          [-4.1930e-03, -3.7756e-03,  6.1542e-03,  ...,  2.7565e-03,\n",
       "            1.7967e-03,  8.5162e-03]]]),\n",
       " 'second_layer_unablated_acts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'second_layer_ablated_acts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'sum_of_f2_diffs': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " 'sum_of_squared_f2_diffs': tensor([2.4058e-10, 6.1355e-10, 4.5209e-09,  ..., 2.8490e-10, 7.5632e-10,\n",
       "         7.5371e-10]),\n",
       " 'sum_of_squared_masked_f2_diffs': tensor([2.4058e-10, 6.1355e-10, 4.5209e-09,  ..., 2.8490e-10, 7.5632e-10,\n",
       "         7.5371e-10]),\n",
       " 'masked_n': tensor([ 42.,  55., 197.,  ...,  15.,  39.,  99.]),\n",
       " 'mean_diffs': tensor([ 3.8312e-11, -1.1198e-10,  3.3833e-10,  ..., -4.2860e-11,\n",
       "          1.5496e-10,  9.6747e-11]),\n",
       " 'm2_diffs': tensor([2.4058e-10, 6.1354e-10, 4.5208e-09,  ..., 2.8490e-10, 7.5632e-10,\n",
       "         7.5371e-10]),\n",
       " 'sum_unablated_f2': tensor([100.6066, 612.8319, 300.3090,  ..., 129.9649, 525.6078, 156.1537]),\n",
       " 'sum_ablated_f2': tensor([100.6065, 612.8320, 300.3090,  ..., 129.9649, 525.6078, 156.1537]),\n",
       " 'masked_means': tensor([ 2.3913e-07, -5.3373e-07,         nan,  ...,         nan,\n",
       "                 nan,         nan]),\n",
       " 'masked_m2': tensor([1.3065e-07, 1.1446e-06,        nan,  ...,        nan,        nan,\n",
       "                nan]),\n",
       " 'mse': tensor([9.1774e-16, 2.3405e-15, 1.7246e-14,  ..., 1.0868e-15, 2.8851e-15,\n",
       "         2.8752e-15]),\n",
       " 'masked_mse': tensor([5.7281e-12, 1.1155e-11, 2.2949e-11,  ..., 1.8993e-11, 1.9393e-11,\n",
       "         7.6132e-12]),\n",
       " 'variances': tensor([9.1774e-16, 2.3405e-15, 1.7246e-14,  ..., 1.0868e-15, 2.8851e-15,\n",
       "         2.8752e-15]),\n",
       " 'std_devs': tensor([3.0294e-08, 4.8379e-08, 1.3132e-07,  ..., 3.2967e-08, 5.3713e-08,\n",
       "         5.3621e-08]),\n",
       " 'masked_variances': tensor([3.1108e-09, 2.0812e-08,        nan,  ...,        nan,        nan,\n",
       "                nan]),\n",
       " 'masked_stdevs': tensor([3.0294e-08, 4.8379e-08, 1.3132e-07,  ..., 3.2967e-08, 5.3713e-08,\n",
       "         5.3621e-08])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['layer_0_feat_4580']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = result['layer_0_feat_4580']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sae_errors': tensor([[[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "            3.3407e-04,  1.0646e-03],\n",
       "          [-5.1186e-03,  1.8308e-02,  5.6459e-03,  ..., -2.9386e-03,\n",
       "            5.5855e-03,  4.7449e-03],\n",
       "          [ 1.3691e-03, -3.9159e-03, -2.5745e-04,  ...,  1.3716e-03,\n",
       "            1.3642e-03,  1.4481e-03],\n",
       "          ...,\n",
       "          [ 2.6384e-04, -1.4210e-03,  4.6958e-03,  ...,  2.7325e-03,\n",
       "            2.6579e-04,  3.6625e-03],\n",
       "          [ 9.2445e-04,  3.0203e-03,  4.8355e-03,  ...,  1.2169e-04,\n",
       "            1.1595e-03, -1.1107e-03],\n",
       "          [-5.7736e-02, -1.0445e-01,  6.6852e-03,  ..., -2.1304e-02,\n",
       "           -7.3209e-02, -4.2357e-02]],\n",
       " \n",
       "         [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "            3.3407e-04,  1.0646e-03],\n",
       "          [ 1.6750e-03, -2.3648e-03,  1.4567e-03,  ...,  4.4935e-03,\n",
       "            4.8193e-03, -1.1140e-03],\n",
       "          [ 1.9542e-03, -2.1624e-03,  1.0924e-02,  ..., -4.6064e-04,\n",
       "           -9.1030e-04,  1.9664e-03],\n",
       "          ...,\n",
       "          [-7.2949e-04, -1.8254e-03,  1.2728e-02,  ...,  3.5381e-03,\n",
       "            4.6094e-03,  6.9130e-03],\n",
       "          [ 3.4838e-03,  3.3630e-03,  7.3133e-03,  ...,  2.0694e-03,\n",
       "            4.8414e-03, -1.3369e-03],\n",
       "          [ 2.4466e-02,  1.5942e-02, -1.1117e-02,  ...,  4.7267e-02,\n",
       "           -7.5200e-02,  3.6721e-02]],\n",
       " \n",
       "         [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "            3.3407e-04,  1.0646e-03],\n",
       "          [-8.5151e-04, -2.3837e-03,  7.6306e-03,  ...,  1.4611e-03,\n",
       "           -8.7495e-04,  1.6211e-03],\n",
       "          [-6.9034e-04, -8.5071e-04, -3.8391e-03,  ...,  3.0022e-04,\n",
       "            4.7869e-03,  1.6768e-04],\n",
       "          ...,\n",
       "          [ 1.5571e-02, -4.1898e-02, -7.9068e-02,  ...,  1.5739e-01,\n",
       "           -7.3942e-02,  1.3117e-01],\n",
       "          [ 2.7662e-03, -1.8523e-03,  1.1043e-02,  ..., -3.2129e-03,\n",
       "           -4.9564e-04, -8.6992e-03],\n",
       "          [ 5.2259e-02, -8.6767e-02,  2.6227e-03,  ...,  3.0250e-03,\n",
       "            3.8609e-02,  4.7577e-02]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "            3.3407e-04,  1.0646e-03],\n",
       "          [ 6.1225e-03, -1.9842e-03, -1.2246e-04,  ...,  8.7433e-05,\n",
       "            2.5042e-03,  3.1428e-03],\n",
       "          [-4.9873e-04, -4.5580e-04,  3.5401e-03,  ...,  7.4563e-04,\n",
       "            3.0457e-03, -1.0869e-03],\n",
       "          ...,\n",
       "          [-5.6946e-04,  2.4207e-03,  1.1234e-02,  ...,  1.2232e-02,\n",
       "            1.3113e-03,  2.1727e-04],\n",
       "          [-6.0867e-03,  2.6940e-03,  1.2050e-02,  ..., -8.7109e-03,\n",
       "            7.4895e-03,  1.0219e-02],\n",
       "          [-7.8616e-04, -6.3965e-03,  1.0159e-02,  ...,  6.9328e-03,\n",
       "            1.0533e-04,  6.4381e-03]],\n",
       " \n",
       "         [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "            3.3407e-04,  1.0646e-03],\n",
       "          [-7.1019e-04, -7.6427e-04, -9.5546e-05,  ...,  7.3489e-03,\n",
       "           -5.0640e-04,  5.5953e-03],\n",
       "          [ 6.2035e-04, -4.5643e-03,  1.8236e-03,  ...,  1.8036e-03,\n",
       "            1.8542e-03,  9.1480e-04],\n",
       "          ...,\n",
       "          [-8.0941e-04, -3.5270e-03,  8.3167e-03,  ...,  3.9547e-03,\n",
       "            3.7081e-03,  3.9895e-03],\n",
       "          [ 1.1322e-03,  1.9975e-03,  5.7750e-03,  ..., -1.0320e-03,\n",
       "            2.3754e-03, -3.5826e-04],\n",
       "          [-3.1919e-03, -3.9398e-03,  8.8295e-03,  ...,  3.8699e-03,\n",
       "            2.6743e-03,  5.2993e-03]],\n",
       " \n",
       "         [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "            3.3407e-04,  1.0646e-03],\n",
       "          [-9.7657e-04, -1.5185e-03, -6.8726e-03,  ...,  2.4818e-03,\n",
       "            2.2567e-03,  1.7896e-03],\n",
       "          [-6.9454e-04, -2.3849e-03,  5.4411e-04,  ...,  4.0318e-03,\n",
       "            8.4965e-04,  3.2813e-03],\n",
       "          ...,\n",
       "          [ 3.1123e-04, -9.2459e-03,  1.1593e-02,  ...,  3.9177e-04,\n",
       "            1.5834e-03,  6.1996e-03],\n",
       "          [-4.0504e-03, -3.3954e-03,  4.3334e-03,  ..., -3.0627e-03,\n",
       "            7.0965e-03, -1.8539e-03],\n",
       "          [-4.1930e-03, -3.7756e-03,  6.1542e-03,  ...,  2.7565e-03,\n",
       "            1.7967e-03,  8.5162e-03]]]),\n",
       " 'second_layer_unablated_acts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'second_layer_ablated_acts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       " 'sum_of_f2_diffs': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " 'sum_of_squared_f2_diffs': tensor([2.4058e-10, 6.1355e-10, 4.5209e-09,  ..., 2.8490e-10, 7.5632e-10,\n",
       "         7.5371e-10]),\n",
       " 'sum_of_squared_masked_f2_diffs': tensor([2.4058e-10, 6.1355e-10, 4.5209e-09,  ..., 2.8490e-10, 7.5632e-10,\n",
       "         7.5371e-10]),\n",
       " 'masked_n': tensor([ 42.,  55., 197.,  ...,  15.,  39.,  99.]),\n",
       " 'mean_diffs': tensor([ 3.8312e-11, -1.1198e-10,  3.3833e-10,  ..., -4.2860e-11,\n",
       "          1.5496e-10,  9.6747e-11]),\n",
       " 'm2_diffs': tensor([2.4058e-10, 6.1354e-10, 4.5208e-09,  ..., 2.8490e-10, 7.5632e-10,\n",
       "         7.5371e-10]),\n",
       " 'sum_unablated_f2': tensor([100.6066, 612.8319, 300.3090,  ..., 129.9649, 525.6078, 156.1537]),\n",
       " 'sum_ablated_f2': tensor([100.6065, 612.8320, 300.3090,  ..., 129.9649, 525.6078, 156.1537]),\n",
       " 'masked_means': tensor([ 2.3913e-07, -5.3373e-07,         nan,  ...,         nan,\n",
       "                 nan,         nan]),\n",
       " 'masked_m2': tensor([1.3065e-07, 1.1446e-06,        nan,  ...,        nan,        nan,\n",
       "                nan]),\n",
       " 'mse': tensor([9.1774e-16, 2.3405e-15, 1.7246e-14,  ..., 1.0868e-15, 2.8851e-15,\n",
       "         2.8752e-15]),\n",
       " 'masked_mse': tensor([5.7281e-12, 1.1155e-11, 2.2949e-11,  ..., 1.8993e-11, 1.9393e-11,\n",
       "         7.6132e-12]),\n",
       " 'variances': tensor([9.1774e-16, 2.3405e-15, 1.7246e-14,  ..., 1.0868e-15, 2.8851e-15,\n",
       "         2.8752e-15]),\n",
       " 'std_devs': tensor([3.0294e-08, 4.8379e-08, 1.3132e-07,  ..., 3.2967e-08, 5.3713e-08,\n",
       "         5.3621e-08]),\n",
       " 'masked_variances': tensor([3.1108e-09, 2.0812e-08,        nan,  ...,        nan,        nan,\n",
       "                nan]),\n",
       " 'masked_stdevs': tensor([3.0294e-08, 4.8379e-08, 1.3132e-07,  ..., 3.2967e-08, 5.3713e-08,\n",
       "         5.3621e-08])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'masked_mse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data\u001b[39m.\u001b[39;49mmasked_mse\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'masked_mse'"
     ]
    }
   ],
   "source": [
    "data.masked_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.7281e-12, 1.1155e-11, 2.2949e-11,  ..., 1.8993e-11, 1.9393e-11,\n",
       "        7.6132e-12])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['masked_mse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24576])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['masked_mse'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24576])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['masked_means'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.3913e-07, -5.3373e-07,         nan,  ...,         nan,\n",
       "                nan,         nan])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['masked_means']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'isna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data[\u001b[39m'\u001b[39;49m\u001b[39mmasked_means\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49misna()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'isna'"
     ]
    }
   ],
   "source": [
    "data['masked_means'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20235"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.isnan(data['masked_means']).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52216fff-9561-4b31-91b9-505fdebe9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "pearson_corr_filename = f\"artefacts/similarity_measures/pearson_correlation/res_jb_sae_feature_similarity_pearson_correlation_1M_0.0_0.1.npz\"\n",
    "with open(pearson_corr_filename, 'rb') as data:\n",
    "    interaction_data = np.load(data)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be33419-7d85-4770-8b95-50e7b7fc3ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded device='cpu', d_sae=24576\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "import torch as t\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "if t.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    "d_sae = 24576\n",
    "print(f\"Loaded {device=}, {d_sae=}\")\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05df70-d642-4f5c-90b1-f2ccf13e956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "top_corr_flat_idx = np.load(\"artefacts/sampled_interaction_measures/pearson_correlation/count_1000.npz\")['arr_0']\n",
    "# for all high-value pearson correlations, loading the first feature from each pair in a (num_layers, num_top_features) matrix\n",
    "corr_prev_layer_feat_idxes, corr_next_layer_feat_idxes = (\n",
    "    np.array([\n",
    "        np.unravel_index(top_corr_flat_idx[layer_idx], shape=(d_sae, d_sae))[ordering_idx]\n",
    "        for layer_idx in range(top_corr_flat_idx.shape[0])\n",
    "    ])\n",
    "    for ordering_idx in range(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14525,  9441,  8718, ...,  6073, 10024,  5580],\n",
       "       [22140, 23465, 17663, ...,  2064, 18409,  6703],\n",
       "       [  737, 22060,  6861, ..., 11177,   938,  5063],\n",
       "       ...,\n",
       "       [ 6955,  8016, 14557, ..., 14316, 17437,   221],\n",
       "       [ 4612, 12311, 11774, ..., 22370, 24023,  2251],\n",
       "       [23726, 15936, 13239, ..., 11804,  5984,  7942]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_prev_layer_feat_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_prev_layer_feat_idxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14525,  9441,  8718,  7609,  1555,  2248, 24067,  6076, 21572,\n",
       "       18712, 23330, 10256, 10314, 15015,  8406, 18743,   978, 24361,\n",
       "        1591,  5701,  4270, 20527,  7447,  8949, 20692,  2529,  9724,\n",
       "        4202, 13226, 18420, 17972, 19029, 13489,  1724, 19665, 15420,\n",
       "       21046, 15678, 23551,  7464, 12288,  3898, 14319,  4580,  8023,\n",
       "       14440, 22626, 17819, 23623, 24491, 21745,  4051, 15506,   544,\n",
       "        4734, 23716, 23969, 14599,   132, 19532, 11155, 10614, 16989,\n",
       "       12105,  2282,  5904,  8104, 17174, 20413, 12309, 12984,  3707,\n",
       "       18133,  3996,  4460,  7923, 24475, 24353,  6500, 13216, 21872,\n",
       "       12327,  7558,  9848, 19677, 14927, 17974, 10953, 16991, 16652,\n",
       "       10427, 23496,  3725,  8018,  1505, 23190,   715, 22597,  2469,\n",
       "       24362, 12984, 10297, 23190,  2439,  1162, 14469, 16687,  7011,\n",
       "        4248, 11045,  6040,  3078, 23224,  1737, 16408,  3317, 16092,\n",
       "       21442, 20155, 12240, 16030, 22216,  1839, 13862, 13677,  6872,\n",
       "        5880, 10254, 12381,  7321,  6245, 16271, 17809, 12817, 14915,\n",
       "       12674,  1839, 12191,  8816,  8384, 15033,  5286, 13873, 18240,\n",
       "       12521, 16229,  6973,  5372,  4649,  2647,  5713,  1855, 16901,\n",
       "       18842, 23967, 23871,  6383, 18545,  9465, 23384, 19823, 15473,\n",
       "        6077,    33,  4689,  8676, 12129, 10899,  3317, 17178,  1995,\n",
       "       20356,  1722, 20517, 16413, 22936, 11029,  3603, 17939, 15032,\n",
       "        7845, 10647,    24, 10612, 16809,  8868, 19323, 11876,    33,\n",
       "       18589,  2166, 24123,  3240, 14129, 11242,  4579,  8424, 19291,\n",
       "        9725,  8658, 11703,    38, 22819, 23250, 15720, 10188,  1681,\n",
       "       13584, 12008,  7702, 14548, 15821,  9132, 17318,  6383, 10325,\n",
       "         235,   626, 15645,  8658,  9462, 10226, 16332,  5384, 23190,\n",
       "       24343, 18774,   727, 23324,  6853, 17068, 15451, 18263, 15840,\n",
       "       14320, 10705,  4707,  4495,  3773, 19169,  5618, 17796, 21309,\n",
       "        9370, 22271,  4359,  9531,  7046,  2695,  5800, 16005,  3470,\n",
       "       21786, 16576, 15667, 11792,  6973, 20567, 14548,  2867,  3994,\n",
       "       10055,  2839, 13983,  7682, 19536,  9478,    29,  1722, 24383,\n",
       "       21711, 11742,  1458,  3305, 17161, 12500,  6112, 16718, 22328,\n",
       "       22000,  1929,  8295, 20406, 10002,  1952, 24182, 20272, 23190,\n",
       "        2580, 20832, 23741, 15222, 16235, 20455,  9883, 12906, 14414,\n",
       "        6609, 20455, 19061,  2667,    24, 24094, 23757, 19545,  5750,\n",
       "       18201,  7215,  6184, 14208, 13954, 14158,  4761, 11835, 21256,\n",
       "        8534, 16143, 17919,  9304, 17540, 17385, 22095, 11118, 19372,\n",
       "       16975, 13070,  9652, 10153, 23713, 22634, 13783,  9413, 15639,\n",
       "        3098, 14119,   842,  3177,  6793, 23739,  7842, 14644,  6233,\n",
       "        3825, 14507, 21295, 19738,  2011,  1050,  7520,  8142, 16129,\n",
       "       11895,   169,  7982, 19446,  6240, 20080, 14968, 15639, 18332,\n",
       "         878,  4772, 12467,   962,  1848, 18972,  4056, 19924, 19739,\n",
       "          33,  9648, 14329, 14559, 19946,  5588,  9146, 16093, 13072,\n",
       "        6383,  8193,  5041,  9260, 15841, 12831, 20188, 16628, 16627,\n",
       "       14052, 11703, 19403,   723, 14649, 24187,  1264, 14132, 10612,\n",
       "        5356,  2288,  5320, 17225,  9895, 18555, 15289,   845, 11307,\n",
       "        7463,  3477, 10439,  6976, 14530, 13903, 10222, 10969, 17799,\n",
       "       14530,  6292, 11674, 14241,  4689, 17776, 22767,  7081, 22614,\n",
       "       15821, 19967,  5269, 21991,  5931, 15773,  1326, 21389, 19065,\n",
       "       13569, 22257, 21551, 22907, 23852, 15531,  8896, 13114,    90,\n",
       "       10393,  8081, 23700, 22483,  9197, 22712, 21992, 22268,  6380,\n",
       "       23639, 13703, 18962, 15797, 24340, 17540, 16506,  7916, 14822,\n",
       "        5610,  4967, 19889, 10684,  9370,  9767,    50, 13502, 17217,\n",
       "       20342, 14844, 10005, 14736,  4229,  9967, 22546,  3655,  7598,\n",
       "       24527, 19685, 12282, 18651, 14345, 19311, 14596,   580,  4090,\n",
       "        5055,  9939, 23418,  4052, 13162, 21788,  2210, 14908,   953,\n",
       "        4334, 20049,  7135, 24103,  8399, 20376, 19222,  5618,  5673,\n",
       "       14830,  2984, 20297, 20764, 22091,  8837, 13601,  4450, 12198,\n",
       "       22761, 23277, 19720, 11785,  2373, 17349, 10156,  6423, 11697,\n",
       "        3443, 22218,  9980, 21251, 12608,  8387,  9256, 14410,  4649,\n",
       "       22035,  1739, 18832,  2133,  7496,  6233, 19003, 13185, 14092,\n",
       "        7638,  8516,  7684, 10779, 15118, 12780, 24399, 20489,  8575,\n",
       "        2104, 20432, 11654, 24524,  2279,  3164, 21933, 16169, 22183,\n",
       "       17902, 15440,  9767,   220,  4834, 21269,  5809,  8224, 23556,\n",
       "        7171, 24081,  4362,   344,  6229, 21552, 17919,  5049,  2967,\n",
       "        1986, 20596, 23669, 14478,  9581,  9559, 24522, 23185, 23675,\n",
       "       22098, 18584, 15397,  7836, 14548, 11320, 13433, 18358,    91,\n",
       "       17677, 22235, 14973, 12381, 11875,  1196,  8261,  7161, 22617,\n",
       "       23518, 10342, 23139, 10516,  9553, 19112, 12880,  3019,  9602,\n",
       "        3192, 17851, 18049, 13269,  1847,  7244,   510, 22062, 20367,\n",
       "       13182,  3536, 10393,  3313,   269, 15376, 14862, 10545,  7724,\n",
       "       19749, 22346, 16580, 11416,  4332,  2341,  9540,  5864, 14353,\n",
       "        2459, 12367, 11099,  8910, 12725,  1448, 10841,  1065,  5094,\n",
       "        7333, 18490,  6271, 18236, 13873, 14548, 23274,   747,  4724,\n",
       "       14976, 20972, 10018, 10570, 10495, 16809, 11690,  1926, 13872,\n",
       "       20713, 21391,    49, 23654,  4606, 13217, 24434, 20281, 17617,\n",
       "        4871, 14515,  2701,  5519, 11855,  1888, 21711,  1742,  3086,\n",
       "        5154, 17854, 22514, 24081, 16322, 18858,  1098,  8648, 13173,\n",
       "       24094,  8732,  6428, 12725, 19768, 21835, 16245,  9145, 20592,\n",
       "       13765, 14000, 20728, 12236, 13834,  1001, 16147, 20001,  9963,\n",
       "       12342,  4398,  7218, 10763, 17722, 16859, 18898, 22886,  3308,\n",
       "       16312,  5311, 14810, 24401,  4052, 13143, 12674, 24171, 23930,\n",
       "       18366, 23436, 22110, 15161,  8115,  5063, 19803,   723, 14207,\n",
       "       21480, 11485, 18994, 22773, 10287,  9168,  8498,  4864, 16103,\n",
       "         347,  5667, 10887, 12248, 20101, 24171,  4708, 10719, 15366,\n",
       "        9588,  6527,  2408,  5629,  5195, 18690,  4525,  9496,   819,\n",
       "       19692, 23103, 10807, 17038, 10297, 21787, 16018, 20424,  7219,\n",
       "        3227, 14541, 10247, 12324,  6920, 10599, 17584, 14264,  5811,\n",
       "       14542,  4674, 13759,  4152, 13243, 24223,  8224, 12947,  9975,\n",
       "       20744,  6716, 13980,  9776,  1563,  6287, 11625,  3997, 18692,\n",
       "        1790, 11783,  1737, 14793,  3878, 10357, 15292, 16103,  1862,\n",
       "       18885, 16716,  9886, 15444, 23185, 18585,  7060, 12824, 18692,\n",
       "       14435,  6271, 16146, 16255,  1936,  2467,  5497, 20592, 20591,\n",
       "        7279, 16295,  4936,  4772, 24055, 16765, 21166, 17558, 15645,\n",
       "        5116, 17167, 11755,  2742, 24511,   455,   706,   648, 22805,\n",
       "        5372,  8387, 16322, 15667, 10349,  5853, 13818, 23450,  4742,\n",
       "       24459, 19770, 13976,  2343,  9208, 13078,  2920, 22899,  8018,\n",
       "        6683, 18317,  5049,  8964,  5249, 11037,  1373, 17905,  3192,\n",
       "        3002, 10812, 11710, 18912, 24332,  3004, 22640, 20239, 12332,\n",
       "        9403,  9019, 22035, 17536,   836, 23800, 22953, 23374, 15008,\n",
       "        7145,  9462, 19494, 23139, 12831, 23135,  9845, 20278, 21997,\n",
       "        7818,   626,  3268, 22024,  1378, 18878, 12880, 15992, 22064,\n",
       "       14113, 17121, 21159, 21388, 21112, 19675,  1345, 20313,  5775,\n",
       "        9413, 20188, 15855, 23136, 16954,  1061, 17333, 11838,  5560,\n",
       "       16446, 21534,  5452, 12718,  3008, 22483, 11876, 13013,  1675,\n",
       "       19692, 19091, 16371,  1182, 17400, 24460,  9875, 14701, 24454,\n",
       "       10474, 15139,  1627, 15346, 23679,  6512, 10671, 18075,  2117,\n",
       "       10144,  3994,  4016,  1294,  6438, 17590,   924, 16777, 17305,\n",
       "       16701, 21665,  7792, 12625,  4306, 19043,  8461, 18139,  1689,\n",
       "        5924,  2749,  9853, 22667,  4650,  3773, 19887, 20270, 15920,\n",
       "       22027,  9309,  4930, 12479, 13614, 14348, 15774, 10142,  4687,\n",
       "       11946,  5612,  3378, 23188,   361, 20188, 19632,  6073, 10024,\n",
       "        5580])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_prev_layer_feat_idxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14525"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_prev_layer_feat_idxes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11914"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_next_layer_feat_idxes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000046"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_data[0][14525][11914]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layer_0_feat_4580': {'sae_errors': tensor([[[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "             3.3407e-04,  1.0646e-03],\n",
       "           [-5.1186e-03,  1.8308e-02,  5.6459e-03,  ..., -2.9386e-03,\n",
       "             5.5855e-03,  4.7449e-03],\n",
       "           [ 1.3691e-03, -3.9159e-03, -2.5745e-04,  ...,  1.3716e-03,\n",
       "             1.3642e-03,  1.4481e-03],\n",
       "           ...,\n",
       "           [ 2.6384e-04, -1.4210e-03,  4.6958e-03,  ...,  2.7325e-03,\n",
       "             2.6579e-04,  3.6625e-03],\n",
       "           [ 9.2445e-04,  3.0203e-03,  4.8355e-03,  ...,  1.2169e-04,\n",
       "             1.1595e-03, -1.1107e-03],\n",
       "           [-5.7736e-02, -1.0445e-01,  6.6852e-03,  ..., -2.1304e-02,\n",
       "            -7.3209e-02, -4.2357e-02]],\n",
       "  \n",
       "          [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "             3.3407e-04,  1.0646e-03],\n",
       "           [ 1.6750e-03, -2.3648e-03,  1.4567e-03,  ...,  4.4935e-03,\n",
       "             4.8193e-03, -1.1140e-03],\n",
       "           [ 1.9542e-03, -2.1624e-03,  1.0924e-02,  ..., -4.6064e-04,\n",
       "            -9.1030e-04,  1.9664e-03],\n",
       "           ...,\n",
       "           [-7.2949e-04, -1.8254e-03,  1.2728e-02,  ...,  3.5381e-03,\n",
       "             4.6094e-03,  6.9130e-03],\n",
       "           [ 3.4838e-03,  3.3630e-03,  7.3133e-03,  ...,  2.0694e-03,\n",
       "             4.8414e-03, -1.3369e-03],\n",
       "           [ 2.4466e-02,  1.5942e-02, -1.1117e-02,  ...,  4.7267e-02,\n",
       "            -7.5200e-02,  3.6721e-02]],\n",
       "  \n",
       "          [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "             3.3407e-04,  1.0646e-03],\n",
       "           [-8.5151e-04, -2.3837e-03,  7.6306e-03,  ...,  1.4611e-03,\n",
       "            -8.7495e-04,  1.6211e-03],\n",
       "           [-6.9034e-04, -8.5071e-04, -3.8391e-03,  ...,  3.0022e-04,\n",
       "             4.7869e-03,  1.6768e-04],\n",
       "           ...,\n",
       "           [ 1.5571e-02, -4.1898e-02, -7.9068e-02,  ...,  1.5739e-01,\n",
       "            -7.3942e-02,  1.3117e-01],\n",
       "           [ 2.7662e-03, -1.8523e-03,  1.1043e-02,  ..., -3.2129e-03,\n",
       "            -4.9564e-04, -8.6992e-03],\n",
       "           [ 5.2259e-02, -8.6767e-02,  2.6227e-03,  ...,  3.0250e-03,\n",
       "             3.8609e-02,  4.7577e-02]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "             3.3407e-04,  1.0646e-03],\n",
       "           [ 6.1225e-03, -1.9842e-03, -1.2246e-04,  ...,  8.7433e-05,\n",
       "             2.5042e-03,  3.1428e-03],\n",
       "           [-4.9873e-04, -4.5580e-04,  3.5401e-03,  ...,  7.4563e-04,\n",
       "             3.0457e-03, -1.0869e-03],\n",
       "           ...,\n",
       "           [-5.6946e-04,  2.4207e-03,  1.1234e-02,  ...,  1.2232e-02,\n",
       "             1.3113e-03,  2.1727e-04],\n",
       "           [-6.0867e-03,  2.6940e-03,  1.2050e-02,  ..., -8.7109e-03,\n",
       "             7.4895e-03,  1.0219e-02],\n",
       "           [-7.8616e-04, -6.3965e-03,  1.0159e-02,  ...,  6.9328e-03,\n",
       "             1.0533e-04,  6.4381e-03]],\n",
       "  \n",
       "          [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "             3.3407e-04,  1.0646e-03],\n",
       "           [-7.1019e-04, -7.6427e-04, -9.5546e-05,  ...,  7.3489e-03,\n",
       "            -5.0640e-04,  5.5953e-03],\n",
       "           [ 6.2035e-04, -4.5643e-03,  1.8236e-03,  ...,  1.8036e-03,\n",
       "             1.8542e-03,  9.1480e-04],\n",
       "           ...,\n",
       "           [-8.0941e-04, -3.5270e-03,  8.3167e-03,  ...,  3.9547e-03,\n",
       "             3.7081e-03,  3.9895e-03],\n",
       "           [ 1.1322e-03,  1.9975e-03,  5.7750e-03,  ..., -1.0320e-03,\n",
       "             2.3754e-03, -3.5826e-04],\n",
       "           [-3.1919e-03, -3.9398e-03,  8.8295e-03,  ...,  3.8699e-03,\n",
       "             2.6743e-03,  5.2993e-03]],\n",
       "  \n",
       "          [[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,\n",
       "             3.3407e-04,  1.0646e-03],\n",
       "           [-9.7657e-04, -1.5185e-03, -6.8726e-03,  ...,  2.4818e-03,\n",
       "             2.2567e-03,  1.7896e-03],\n",
       "           [-6.9454e-04, -2.3849e-03,  5.4411e-04,  ...,  4.0318e-03,\n",
       "             8.4965e-04,  3.2813e-03],\n",
       "           ...,\n",
       "           [ 3.1123e-04, -9.2459e-03,  1.1593e-02,  ...,  3.9177e-04,\n",
       "             1.5834e-03,  6.1996e-03],\n",
       "           [-4.0504e-03, -3.3954e-03,  4.3334e-03,  ..., -3.0627e-03,\n",
       "             7.0965e-03, -1.8539e-03],\n",
       "           [-4.1930e-03, -3.7756e-03,  6.1542e-03,  ...,  2.7565e-03,\n",
       "             1.7967e-03,  8.5162e-03]]]),\n",
       "  'second_layer_unablated_acts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       "  'second_layer_ablated_acts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "  \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       "  'sum_of_f2_diffs': tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       "  'sum_of_squared_f2_diffs': tensor([2.4058e-10, 6.1355e-10, 4.5209e-09,  ..., 2.8490e-10, 7.5632e-10,\n",
       "          7.5371e-10]),\n",
       "  'sum_of_squared_masked_f2_diffs': tensor([2.4058e-10, 6.1355e-10, 4.5209e-09,  ..., 2.8490e-10, 7.5632e-10,\n",
       "          7.5371e-10]),\n",
       "  'masked_n': tensor([ 42.,  55., 197.,  ...,  15.,  39.,  99.]),\n",
       "  'mean_diffs': tensor([ 3.8312e-11, -1.1198e-10,  3.3833e-10,  ..., -4.2860e-11,\n",
       "           1.5496e-10,  9.6747e-11]),\n",
       "  'm2_diffs': tensor([2.4058e-10, 6.1354e-10, 4.5208e-09,  ..., 2.8490e-10, 7.5632e-10,\n",
       "          7.5371e-10]),\n",
       "  'sum_unablated_f2': tensor([100.6066, 612.8319, 300.3090,  ..., 129.9649, 525.6078, 156.1537]),\n",
       "  'sum_ablated_f2': tensor([100.6065, 612.8320, 300.3090,  ..., 129.9649, 525.6078, 156.1537]),\n",
       "  'masked_means': tensor([ 2.3913e-07, -5.3373e-07,         nan,  ...,         nan,\n",
       "                  nan,         nan]),\n",
       "  'masked_m2': tensor([1.3065e-07, 1.1446e-06,        nan,  ...,        nan,        nan,\n",
       "                 nan]),\n",
       "  'mse': tensor([9.1774e-16, 2.3405e-15, 1.7246e-14,  ..., 1.0868e-15, 2.8851e-15,\n",
       "          2.8752e-15]),\n",
       "  'masked_mse': tensor([5.7281e-12, 1.1155e-11, 2.2949e-11,  ..., 1.8993e-11, 1.9393e-11,\n",
       "          7.6132e-12]),\n",
       "  'variances': tensor([9.1774e-16, 2.3405e-15, 1.7246e-14,  ..., 1.0868e-15, 2.8851e-15,\n",
       "          2.8752e-15]),\n",
       "  'std_devs': tensor([3.0294e-08, 4.8379e-08, 1.3132e-07,  ..., 3.2967e-08, 5.3713e-08,\n",
       "          5.3621e-08]),\n",
       "  'masked_variances': tensor([3.1108e-09, 2.0812e-08,        nan,  ...,        nan,        nan,\n",
       "                 nan]),\n",
       "  'masked_stdevs': tensor([3.0294e-08, 4.8379e-08, 1.3132e-07,  ..., 3.2967e-08, 5.3713e-08,\n",
       "          5.3621e-08])}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'masked_stdevs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result[\u001b[39m'\u001b[39;49m\u001b[39mmasked_stdevs\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'masked_stdevs'"
     ]
    }
   ],
   "source": [
    "result['masked_stdevs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['layer_0_feat_4580'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
