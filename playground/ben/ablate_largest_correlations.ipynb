{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.ablate_single_feature import AblationAggregator\n",
    "import numpy as np\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sae = 24576\n",
    "num_layers = 2\n",
    "num_top_feats_to_ablate_per_layer = 1\n",
    "num_batches = 2\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corr_flat_idx = np.load(\"artefacts/ablations/top_1000_pearson_per_layer_flattened_feature_idx.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_idxes, second_layer_idxes = (\n",
    "    np.array([\n",
    "        np.unravel_index(top_corr_flat_idx[layer_idx], shape=(d_sae, d_sae))[ordering_idx]\n",
    "        for layer_idx in range(num_layers)\n",
    "    ])\n",
    "    for ordering_idx in range(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfull_corrs_filename = f\"artefacts/similarity_measures/pearson_correlation/res_jb_sae_feature_similarity_pearson_correlation_1M_0.0_0.1.npz\"\\nwith open(full_corrs_filename, \\'rb\\') as full_corrs_data:\\n    interaction_data = np.load(full_corrs_data)[\\'arr_0\\']\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "full_corrs_filename = f\"artefacts/similarity_measures/pearson_correlation/res_jb_sae_feature_similarity_pearson_correlation_1M_0.0_0.1.npz\"\n",
    "with open(full_corrs_filename, 'rb') as full_corrs_data:\n",
    "    interaction_data = np.load(full_corrs_data)['arr_0']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAEs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.19it/s]\n"
     ]
    }
   ],
   "source": [
    "diff_agg = AblationAggregator(num_batches=num_batches, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diff aggs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to artefacts/ablations/layer_0__feat_14525__num_batches_2__batch_size_2.pth\n",
      "Collecting diff aggs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to artefacts/ablations/layer_1__feat_22140__num_batches_2__batch_size_2.pth\n"
     ]
    }
   ],
   "source": [
    "for layer_idx in range(num_layers):\n",
    "    for feat_idx_idx in range(num_top_feats_to_ablate_per_layer):\n",
    "        feat_idx = first_layer_idxes[layer_idx][feat_idx_idx]\n",
    "        diff_agg.aggregate(first_layer_idx=layer_idx, feature_idx=feat_idx)\n",
    "        diff_agg.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = t.load(\"artefacts/ablations/layer_1__feat_22140__num_batches_2__batch_size_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sae_errors': tensor([[[ 2.2111e-02, -5.7451e-05, -2.5705e-02,  ...,  1.1873e-02,\n",
       "            2.0010e-02,  2.6804e-02],\n",
       "          [ 1.2717e-01, -2.0407e-02,  1.3241e-02,  ...,  1.9818e-01,\n",
       "            1.7069e-01,  3.0815e-01],\n",
       "          [-2.7285e-02, -2.1284e-01,  1.5735e-01,  ..., -1.0589e-01,\n",
       "           -8.2683e-03,  2.4485e-01],\n",
       "          ...,\n",
       "          [-1.9970e-01,  5.6876e-02,  1.2383e-01,  ...,  1.4916e-02,\n",
       "            1.1262e-01, -1.0566e-02],\n",
       "          [-9.3437e-02,  1.5273e-01,  3.3676e-01,  ...,  5.0143e-02,\n",
       "            1.3351e-02,  8.3357e-02],\n",
       "          [ 7.3128e-02,  4.0250e-02, -1.4088e-01,  ...,  1.4469e-01,\n",
       "            2.6083e-01,  7.4071e-02]],\n",
       " \n",
       "         [[ 2.2111e-02, -5.7451e-05, -2.5705e-02,  ...,  1.1873e-02,\n",
       "            2.0010e-02,  2.6804e-02],\n",
       "          [-1.1497e-01,  1.9717e-01,  4.4937e-02,  ..., -2.7973e-02,\n",
       "            1.5322e-01, -7.6398e-02],\n",
       "          [ 1.3685e-02, -2.5629e-01, -7.6623e-02,  ..., -4.0273e-01,\n",
       "            1.5220e-01, -6.7656e-02],\n",
       "          ...,\n",
       "          [-1.1249e-01,  1.5189e-01, -5.9271e-02,  ..., -5.9736e-02,\n",
       "           -2.5092e-02, -7.0661e-02],\n",
       "          [-1.7786e-01,  7.8242e-02,  5.3163e-02,  ...,  5.5822e-02,\n",
       "            8.6243e-03, -1.1863e-01],\n",
       "          [-1.6478e-02,  2.2747e-03,  1.3622e-01,  ...,  2.2196e-01,\n",
       "            7.5175e-03,  1.1818e-01]]], device='mps:0'),\n",
       " 'second_layer_unablated_acts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='mps:0'),\n",
       " 'second_layer_ablated_acts': tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], device='mps:0'),\n",
       " 'sum_of_f2_diffs': tensor([0., 0., 0.,  ..., 0., 0., 0.], device='mps:0'),\n",
       " 'sum_of_squared_f2_diffs': tensor([0.0000, 0.0000, 0.0000,  ..., 0.0090, 0.0000, 0.0000], device='mps:0'),\n",
       " 'sum_of_squared_masked_f2_diffs': tensor([0.0000, 0.0000, 0.0000,  ..., 0.0088, 0.0000, 0.0000], device='mps:0'),\n",
       " 'masked_n': tensor([0., 0., 0.,  ..., 1., 0., 0.], device='mps:0'),\n",
       " 'mean_diffs': tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.0002,  0.0000,  0.0000],\n",
       "        device='mps:0'),\n",
       " 'm2_diffs': tensor([0.0000, 0.0000, 0.0000,  ..., 0.0089, 0.0000, 0.0000], device='mps:0'),\n",
       " 'sum_unablated_f2': tensor([0.0000, 0.0000, 0.0000,  ..., 0.1123, 0.0000, 0.0000], device='mps:0'),\n",
       " 'sum_ablated_f2': tensor([0.0000, 0.0000, 0.0000,  ..., 0.2199, 0.0000, 0.0000], device='mps:0'),\n",
       " 'masked_means': tensor([nan, nan, nan,  ..., nan, nan, nan], device='mps:0'),\n",
       " 'masked_m2': tensor([nan, nan, nan,  ..., nan, nan, nan], device='mps:0'),\n",
       " 'mse': tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.7520e-05, 0.0000e+00,\n",
       "         0.0000e+00], device='mps:0'),\n",
       " 'masked_mse': tensor([   nan,    nan,    nan,  ..., 0.0088,    nan,    nan], device='mps:0'),\n",
       " 'variances': tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.7476e-05, 0.0000e+00,\n",
       "         0.0000e+00], device='mps:0'),\n",
       " 'std_devs': tensor([0.0000, 0.0000, 0.0000,  ..., 0.0042, 0.0000, 0.0000], device='mps:0'),\n",
       " 'masked_variances': tensor([nan, nan, nan,  ..., nan, nan, nan], device='mps:0'),\n",
       " 'masked_stdevs': tensor([0.0000, 0.0000, 0.0000,  ..., 0.0042, 0.0000, 0.0000], device='mps:0')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sae_errors', 'second_layer_unablated_acts', 'second_layer_ablated_acts', 'sum_of_f2_diffs', 'sum_of_squared_f2_diffs', 'sum_of_squared_masked_f2_diffs', 'masked_n', 'mean_diffs', 'm2_diffs', 'sum_unablated_f2', 'sum_ablated_f2', 'masked_means', 'masked_m2', 'mse', 'masked_mse', 'variances', 'std_devs', 'masked_variances', 'masked_stdevs'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
