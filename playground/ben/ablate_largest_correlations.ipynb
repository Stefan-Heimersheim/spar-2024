{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded device='mps'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benlerner/work/spar-2024/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from experiments.ablate_single_feature import AblationAggregator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sae = 24576\n",
    "num_layers = 11\n",
    "num_top_feats_to_ablate_per_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corr_flat_idx = np.load(\"artefacts/ablations/top_1000_pearson_per_layer_flattened_feature_idx.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_idxes, second_layer_idxes = (\n",
    "    np.array([\n",
    "        np.unravel_index(top_corr_flat_idx[layer_idx], shape=(d_sae, d_sae))[ordering_idx]\n",
    "        for layer_idx in range(num_layers)\n",
    "    ])\n",
    "    for ordering_idx in range(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_corrs_filename = f\"artefacts/similarity_measures/pearson_correlation/res_jb_sae_feature_similarity_pearson_correlation_1M_0.0_0.1.npz\"\n",
    "with open(full_corrs_filename, 'rb') as full_corrs_data:\n",
    "    interaction_data = np.load(full_corrs_data)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99695206"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_idx = 0\n",
    "feature_pair_idx = 500\n",
    "interaction_data[layer_idx, first_layer_idxes[layer_idx][feature_pair_idx], second_layer_idxes[layer_idx][feature_pair_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SAEs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 12/12 [00:05<00:00,  2.28it/s]\n"
     ]
    }
   ],
   "source": [
    "diff_agg = AblationAggregator(num_batches=2, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diff aggs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ablation activation aggs\n"
     ]
    }
   ],
   "source": [
    "diff_agg.aggregate(first_layer_idx=0, feature_idx=2)\n",
    "diff_agg.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import wat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: AblationAggregator(num_batches=2, batch_size=2, model=HookedTransformer(\n",
      "  (embed): Embed()\n",
      "  (hook_embed): HookPoint()\n",
      "  (pos_embed): PosEmbed()\n",
      "  (hook_pos_embed): HookPoint()\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x TransformerBlock(\n",
      "      (ln1): LayerNormPre(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (ln2): LayerNormPre(\n",
      "        (hook_scale): HookPoint()\n",
      "        (hook_normalized): HookPoint()\n",
      "      )\n",
      "      (attn): Attention(\n",
      "        (hook_k): HookPoint()\n",
      "        (hook_q): HookPoint()\n",
      "        (hook_v): HookPoint()\n",
      "        (hook_z): HookPoint()\n",
      "        (hook_attn_scores): HookPoint()\n",
      "        (hook_pattern): HookPoint()\n",
      "        (hook_result): HookPoint()\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (hook_pre): HookPoint()\n",
      "        (hook_post): HookPoint()\n",
      "      )\n",
      "      (hook_attn_in): HookPoint()\n",
      "      (hook_q_input): HookPoint()\n",
      "      (hook_k_input): HookPoint()\n",
      "      (hook_v_input): HookPoint()\n",
      "      (hook_mlp_in): HookPoint()\n",
      "      (hook_attn_out): HookPoint()\n",
      "      (hook_mlp_out): HookPoint()\n",
      "      (hook_resid_pre): HookPoint()\n",
      "      (hook_resid_mid): HookPoint()\n",
      "      (hook_resid_post): HookPoint()\n",
      "    )\n",
      "  )\n",
      "  (ln_final): LayerNormPre(\n",
      "    (hook_scale): HookPoint()\n",
      "    (hook_normalized): HookPoint()\n",
      "  )\n",
      "  (unembed): Unembed()\n",
      "))\n",
      "type: experiments.ablate_single_feature.AblationAggregator\n",
      "\n",
      "Public attributes:\n",
      "  batch_size: int = 2\n",
      "  context_size: int = 128\n",
      "  d_sae: int = 24576\n",
      "  feature_idx: int = 2\n",
      "  first_layer_idx: int = 0\n",
      "  m2_diffs: torch.Tensor = tensor([0.0000e+00, 1.3071e-10, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,…\n",
      "  masked_m2: torch.Tensor = tensor([       nan, 3.3397e-08,        nan,  ...,        nan,        nan,…\n",
      "  masked_means: torch.Tensor = tensor([        nan, -1.1444e-05,         nan,  ...,         nan,…\n",
      "  masked_mse: torch.Tensor = tensor([       nan, 1.3097e-10,        nan,  ...,        nan,        nan,…\n",
      "  masked_n: torch.Tensor = tensor([0., 1., 0.,  ..., 0., 0., 0.], device='mps:0')\n",
      "  masked_stdevs: torch.Tensor = tensor([0.0000e+00, 5.0527e-07, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,…\n",
      "  masked_variances: torch.Tensor = tensor([       nan, 3.3397e-08,        nan,  ...,        nan,        nan,…\n",
      "  mean_diffs: torch.Tensor = tensor([ 0.0000e+00, -2.2352e-08,  0.0000e+00,  ...,  0.0000e+00,…\n",
      "  min_activation_tol: float = 1e-15\n",
      "  mse: torch.Tensor = tensor([0.0000e+00, 2.5580e-13, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,…\n",
      "  n_total: int = 512\n",
      "  num_batches: int = 2\n",
      "  num_tokens_per_batch: int = 256\n",
      "  prepend_bos: bool = True\n",
      "  sae_errors: torch.Tensor = tensor([[[ 3.6886e-04, -9.5102e-04,  1.5796e-03,  ...,  1.5465e-03,…\n",
      "  sae_id_to_sae: dict = {…\n",
      "  second_layer_ablated_acts: torch.Tensor = tensor([[[0., 0., 0.,  ..., 0., 0., 0.],…\n",
      "  second_layer_unablated_acts: torch.Tensor = tensor([[[0., 0., 0.,  ..., 0., 0., 0.],…\n",
      "  std_devs: torch.Tensor = tensor([0.0000e+00, 5.0527e-07, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,…\n",
      "  sum_ablated_f2: torch.Tensor = tensor([ 0.0000, 25.1172,  0.0000,  ...,  0.0000,  0.0000,  0.0000],…\n",
      "  sum_of_f2_diffs: torch.Tensor = tensor([0., 0., 0.,  ..., 0., 0., 0.], device='mps:0')\n",
      "  sum_of_squared_f2_diffs: torch.Tensor = tensor([0.0000e+00, 1.3097e-10, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,…\n",
      "  sum_of_squared_masked_f2_diffs: torch.Tensor = tensor([0.0000e+00, 1.3097e-10, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,…\n",
      "  sum_unablated_f2: torch.Tensor = tensor([ 0.0000, 25.1172,  0.0000,  ...,  0.0000,  0.0000,  0.0000],…\n",
      "  variances: torch.Tensor = tensor([0.0000e+00, 2.5530e-13, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,…\n",
      "\n",
      "  def ablate_and_reconstruct_with_errors(activations: torch.Tensor, hook: transformer_lens.hook_points.HookPoint, feature_idx: int)\n",
      "  def aggregate(first_layer_idx: int, feature_idx: int)\n",
      "  def create_id_to_sae() -> Dict[str, sae_lens.sae.SAE]\n",
      "  model(*args, **kwargs) # Hooked Transformer.…\n",
      "  def save()\n",
      "  def save_error_terms(activations: torch.Tensor, hook: transformer_lens.hook_points.HookPoint) -> torch.Tensor\n",
      "  def save_second_layer_acts(activations: torch.Tensor, hook: transformer_lens.hook_points.HookPoint, ablated: bool)\n",
      "\n",
      "Private attributes:\n",
      "  def _finalize()\n",
      "  def _load_data() -> torch.utils.data.dataloader.DataLoader\n",
      "  def _process_global_second_layer_acts() # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm…\n"
     ]
    }
   ],
   "source": [
    "wat / diff_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
