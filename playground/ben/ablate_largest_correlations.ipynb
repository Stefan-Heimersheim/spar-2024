{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded device='mps'\n",
      "Loading SAEs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benlerner/work/spar-2024/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 12/12 [00:04<00:00,  2.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from experiments.ablate_single_feature import create_diff_agg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sae = 24576\n",
    "num_layers = 11\n",
    "num_top_feats_to_ablate_per_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corr_flat_idx = np.load(\"artefacts/ablations/top_1000_pearson_per_layer_flattened_feature_idx.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_idxes, second_layer_idxes = (\n",
    "    np.array([\n",
    "        np.unravel_index(top_corr_flat_idx[layer_idx], shape=(d_sae, d_sae))[ordering_idx]\n",
    "        for layer_idx in range(num_layers)\n",
    "    ])\n",
    "    for ordering_idx in range(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11914, 22737, 11914, ..., 14723,  2140, 20921],\n",
       "       [19595,  1151,  1151, ..., 22164, 13941, 15256],\n",
       "       [22017, 10228,  6126, ...,  5161,  7935,  1626],\n",
       "       ...,\n",
       "       [ 4612, 22003,  4612, ..., 21342, 14041, 10852],\n",
       "       [19615,  4268, 19615, ..., 14463, 12118,  7344],\n",
       "       [12555,  8032, 11266, ...,  7186,  9918, 17060]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_layer_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_corrs_filename = f\"artefacts/similarity_measures/pearson_correlation/res_jb_sae_feature_similarity_pearson_correlation_1M_0.0_0.1.npz\"\n",
    "with open(full_corrs_filename, 'rb') as full_corrs_data:\n",
    "    interaction_data = np.load(full_corrs_data)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99695206"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_idx = 0\n",
    "feature_pair_idx = 500\n",
    "interaction_data[layer_idx, first_layer_idxes[layer_idx][feature_pair_idx], second_layer_idxes[layer_idx][feature_pair_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diff aggs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.37s/it]\n"
     ]
    }
   ],
   "source": [
    "diff_agg = create_diff_agg(first_layer_idx=0, feature_idx=2, num_batches=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: <experiments.ablate_single_feature.Aggregator object at 0x315f39220>\n",
      "type: experiments.ablate_single_feature.Aggregator\n",
      "\n",
      "Public attributes:\n",
      "  m2_diffs: torch.Tensor = tensor([1.3095e-10, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 4.6038e-12,…\n",
      "  masked_m2: torch.Tensor = tensor([5.3631e-07, 0.0000e+00,        nan,  ...,        nan,        nan,…\n",
      "  masked_means: torch.Tensor = tensor([1.1444e-05, 0.0000e+00,        nan,  ...,        nan,        nan,…\n",
      "  masked_mse: torch.Tensor = tensor([1.3097e-10, 0.0000e+00,        nan,  ...,        nan, 4.6043e-12,…\n",
      "  masked_n: torch.Tensor = tensor([1., 2., 0.,  ..., 0., 1., 0.], device='mps:0')\n",
      "  masked_stdevs: torch.Tensor = tensor([1.2643e-07, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 2.3706e-08,…\n",
      "  masked_variances: torch.Tensor = tensor([5.3631e-07, 0.0000e+00,        nan,  ...,        nan,        nan,…\n",
      "  mean_diffs: torch.Tensor = tensor([ 1.3970e-09,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,…\n",
      "  min_activation_tol: float = 1e-15\n",
      "  mse: torch.Tensor = tensor([1.5987e-14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 5.6205e-16,…\n",
      "  n_total: int = 8192\n",
      "  num_tokens_per_batch: int = 4096\n",
      "  std_devs: torch.Tensor = tensor([1.2643e-07, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 2.3706e-08,…\n",
      "  sum_ablated_f2: torch.Tensor = tensor([33.6496, 50.5621,  0.0000,  ...,  0.0000,  2.1612,  0.0000],…\n",
      "  sum_of_f2_diffs: torch.Tensor = tensor([0., 0., 0.,  ..., 0., 0., 0.], device='mps:0')\n",
      "  sum_of_squared_f2_diffs: torch.Tensor = tensor([1.3097e-10, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 4.6043e-12,…\n",
      "  sum_of_squared_masked_f2_diffs: torch.Tensor = tensor([1.3097e-10, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 4.6043e-12,…\n",
      "  sum_unablated_f2: torch.Tensor = tensor([33.6496, 50.5621,  0.0000,  ...,  0.0000,  2.1612,  0.0000],…\n",
      "  variances: torch.Tensor = tensor([1.5985e-14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 5.6198e-16,…\n",
      "\n",
      "  def finalize()\n",
      "  def process_global_second_layer_acts() # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm…\n",
      "  def save(num_batches)\n"
     ]
    }
   ],
   "source": [
    "wat / diff_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
