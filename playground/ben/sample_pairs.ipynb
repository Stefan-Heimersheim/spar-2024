{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff42d9b-aa41-4e2e-b29f-0a530e4cd7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--measure MEASURE] [--truncate TRUNCATE]\n",
      "                             [--save | --no-save]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/benlerner/Library/Jupyter/runtime/kernel-v2-89379YvuwkwZMG5Dt.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benlerner/work/spar-2024/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from src.enums import Measure\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--measure', type=Measure, help='interaction measure whose values will indicate the', default=Measure.pearson)\n",
    "    parser.add_argument('--truncate', type=bool, help='truncates the number of feature pairs that are sampled, used only for testing bc its fast', default=False)\n",
    "    parser.add_argument('--save', type=bool, help='whether to save results or not', action=argparse.BooleanOptionalAction, default=False)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(\"Reading full interaction scores\")\n",
    "    if args.measure == Measure.pearson:\n",
    "        filename = \"artefacts/similarity_measures/pearson_correlation/res_jb_sae_feature_similarity_pearson_correlation_1M_0.0_0.1.npz\"\n",
    "        with open(filename, 'rb') as data:\n",
    "            interaction_scores = np.load(data)['arr_0']\n",
    "    elif args.measure == Measure.jaccard:\n",
    "        filename = \"artefacts/jaccard/jaccard_2024-07-02-a.npz\"\n",
    "        with open(filename, 'rb') as data:\n",
    "            interaction_scores = np.load(data)['arr_0']\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Haven't gotten around to {args.measure} yet\")\n",
    "    num_layers, d_sae, _ = interaction_scores.shape\n",
    "\n",
    "    flattened_per_layer_scores = interaction_scores.reshape(num_layers, d_sae**2)\n",
    "    if args.truncate:\n",
    "        flattened_per_layer_scores = flattened_per_layer_scores[:,:100000]\n",
    "    \n",
    "    # key line, very slow\n",
    "    print(\"Sorting each layer\")\n",
    "    sorted_by_score_per_layer_pair_idxes = np.argsort(flattened_per_layer_scores, axis=1)\n",
    "\n",
    "    layer_indices = np.arange(num_layers)[:, np.newaxis]\n",
    "\n",
    "    num_pairs_to_sample = 1000\n",
    "    _, curr_num_pairs_per_layer =  sorted_by_score_per_layer_pair_idxes.shape\n",
    "    lower_bound_idx = int(curr_num_pairs_per_layer * 0.2)\n",
    "    step_size = (curr_num_pairs_per_layer - lower_bound_idx) // num_pairs_to_sample\n",
    "\n",
    "    # getting evenly spaced samples, as per https://docs.google.com/document/d/1nTVtRB9qgXsNb0NtERamyvi8a9J8MH1Q2RH17PR3iDo/edit#bookmark=id.nd6kw9yrxctg\n",
    "    \n",
    "    output_filename = f\"artefacts/sampled_interaction_measures/{args.measure.value}/count_{num_pairs_to_sample}\" \n",
    "\n",
    "    if args.save:\n",
    "        print(f\"Saving sampled pairs per layer\")\n",
    "        np.save(\n",
    "            output_filename,\n",
    "            sorted_by_score_per_layer_pair_idxes[:, lower_bound_idx::step_size]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc2082-a919-415a-9d77-4da9d2f9cc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--measure MEASURE] [--truncate TRUNCATE]\n",
      "                             [--save | --no-save]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/benlerner/Library/Jupyter/runtime/kernel-v2-89379YvuwkwZMG5Dt.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "# %% tb\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from src.enums import Measure\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--measure', type=Measure, help='interaction measure whose values will indicate the', default=Measure.pearson)\n",
    "    parser.add_argument('--truncate', type=bool, help='truncates the number of feature pairs that are sampled, used only for testing bc its fast', default=False)\n",
    "    parser.add_argument('--save', type=bool, help='whether to save results or not', action=argparse.BooleanOptionalAction, default=False)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    print(\"Reading full interaction scores\")\n",
    "    if args.measure == Measure.pearson:\n",
    "        filename = \"artefacts/similarity_measures/pearson_correlation/res_jb_sae_feature_similarity_pearson_correlation_1M_0.0_0.1.npz\"\n",
    "        with open(filename, 'rb') as data:\n",
    "            interaction_scores = np.load(data)['arr_0']\n",
    "    elif args.measure == Measure.jaccard:\n",
    "        filename = \"artefacts/jaccard/jaccard_2024-07-02-a.npz\"\n",
    "        with open(filename, 'rb') as data:\n",
    "            interaction_scores = np.load(data)['arr_0']\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Haven't gotten around to {args.measure} yet\")\n",
    "    num_layers, d_sae, _ = interaction_scores.shape\n",
    "\n",
    "    flattened_per_layer_scores = interaction_scores.reshape(num_layers, d_sae**2)\n",
    "    if args.truncate:\n",
    "        flattened_per_layer_scores = flattened_per_layer_scores[:,:100000]\n",
    "    \n",
    "    # key line, very slow\n",
    "    print(\"Sorting each layer\")\n",
    "    sorted_by_score_per_layer_pair_idxes = np.argsort(flattened_per_layer_scores, axis=1)\n",
    "\n",
    "    layer_indices = np.arange(num_layers)[:, np.newaxis]\n",
    "\n",
    "    num_pairs_to_sample = 1000\n",
    "    _, curr_num_pairs_per_layer =  sorted_by_score_per_layer_pair_idxes.shape\n",
    "    lower_bound_idx = int(curr_num_pairs_per_layer * 0.2)\n",
    "    step_size = (curr_num_pairs_per_layer - lower_bound_idx) // num_pairs_to_sample\n",
    "\n",
    "    # getting evenly spaced samples, as per https://docs.google.com/document/d/1nTVtRB9qgXsNb0NtERamyvi8a9J8MH1Q2RH17PR3iDo/edit#bookmark=id.nd6kw9yrxctg\n",
    "    \n",
    "    output_filename = f\"artefacts/sampled_interaction_measures/{args.measure.value}/count_{num_pairs_to_sample}\" \n",
    "\n",
    "    if args.save:\n",
    "        print(f\"Saving sampled pairs per layer\")\n",
    "        np.save(\n",
    "            output_filename,\n",
    "            sorted_by_score_per_layer_pair_idxes[:, lower_bound_idx::step_size]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from math import prod\n",
    "from src.enums import Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"artefacts/similarity_measures/pearson_correlation/res_jb_sae_feature_similarity_pearson_correlation_1M_0.0_0.1.npz\"\n",
    "with open(filename, 'rb') as data:\n",
    "    interaction_scores = np.load(data)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting each layer\n"
     ]
    }
   ],
   "source": [
    "num_layers, d_sae, _ = interaction_scores.shape\n",
    "\n",
    "flattened_per_layer_scores = interaction_scores.reshape(num_layers, d_sae**2)\n",
    "if True:\n",
    "    flattened_per_layer_scores = flattened_per_layer_scores[:,:10000000]\n",
    "\n",
    "# key line, very slow\n",
    "print(\"Sorting each layer\")\n",
    "sorted_by_score_per_layer_pair_idxes = np.argsort(flattened_per_layer_scores, axis=1)\n",
    "\n",
    "layer_indices = np.arange(num_layers)[:, np.newaxis]\n",
    "\n",
    "num_pairs_to_sample = 1000\n",
    "_, curr_num_pairs_per_layer =  sorted_by_score_per_layer_pair_idxes.shape\n",
    "lower_bound_idx = int(curr_num_pairs_per_layer * 0.2)\n",
    "step_size = (curr_num_pairs_per_layer - lower_bound_idx) // num_pairs_to_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4350.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.count_nonzero(flattened_per_layer_scores) / prod(sorted_by_score_per_layer_pair_idxes.shape)) * sorted_by_score_per_layer_pair_idxes.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 24576, 24576)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"artefacts/similarity_measures/pearson_correlation/res_jb_sae_feature_similarity_pearson_correlation_1M_0.0_0.1.npz\"\n",
    "with open(filename, 'rb') as data:\n",
    "    interaction_scores = np.load(data)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_sae = 24576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([244, 244, 243, 243, 252, 252, 252, 251, 251, 253, 254, 254, 252,\n",
       "        253, 249, 249, 249, 248, 248, 250, 250, 249, 249, 249, 233, 233,\n",
       "        232, 232, 232, 234, 235, 233, 234, 234, 229, 230, 229, 229, 229,\n",
       "        231, 231, 230, 231, 239, 239, 239, 238, 239, 241, 240, 241, 240,\n",
       "        240, 236, 236, 236, 235, 235, 237, 238, 238, 236, 237, 373, 373,\n",
       "        372, 372, 372, 374, 375, 373, 373, 374, 369, 370, 369, 369, 369,\n",
       "        371, 371, 370, 370, 379, 379, 379, 378, 379, 380, 380, 381, 379,\n",
       "        380, 376, 376, 376, 375, 375, 377, 378, 378, 376, 377, 360, 360,\n",
       "        359, 359, 359, 361, 362, 361, 360, 361, 356, 357, 356, 356, 356,\n",
       "        358, 358, 358, 358, 358, 366, 366, 365, 366, 368, 368, 368, 367,\n",
       "        367, 363, 363, 363, 362, 363, 365, 365, 365, 364, 364, 398, 398,\n",
       "        398, 397, 397, 400, 400, 399, 399, 399, 395, 395, 394, 394, 394,\n",
       "        396, 397, 396, 396, 396, 404, 404, 404, 404, 406, 406, 406, 405,\n",
       "        406, 401, 401, 401, 400, 401, 403, 403, 403, 402, 402, 385, 386,\n",
       "        385, 384, 385, 387, 387, 386, 386, 386, 382, 383, 381, 381, 382,\n",
       "        383, 384, 383, 383, 383, 391, 392, 391, 391, 391, 393, 393, 392,\n",
       "        393, 388, 388, 389, 387, 388, 390, 390, 390, 389, 390, 322, 322,\n",
       "        322, 321, 321, 323, 324, 323, 322, 323, 319, 319, 318, 318, 318,\n",
       "        320, 321, 319, 320, 320, 328, 328, 327, 328, 327, 329, 330, 329,\n",
       "        329, 325, 325, 325, 324, 324, 326, 326, 327, 325, 326, 309, 309,\n",
       "        309, 308, 309, 311, 311, 311, 310, 310, 306, 306, 305, 305, 305,\n",
       "        307, 308, 306, 306, 307, 315, 316, 314, 315, 315, 317, 317, 316,\n",
       "        316, 316, 312, 312, 311, 312, 314, 314, 314, 313, 313, 347, 347,\n",
       "        347, 346, 347, 349, 349, 349, 348, 348, 344, 344, 344, 343, 343,\n",
       "        346, 346, 345, 345, 345, 353, 354, 353, 353, 353, 355, 355, 354,\n",
       "        355, 354, 350, 350, 349, 350, 352, 352, 352, 351, 352, 334, 334,\n",
       "        335, 333, 334, 336, 336, 336, 335, 336, 331, 332, 331, 330, 331,\n",
       "        333, 333, 332, 332, 332, 341, 341, 340, 340, 340, 342, 343, 341,\n",
       "        342, 342, 337, 338, 337, 337, 337, 339, 339, 338, 339,  67,  67,\n",
       "         68,  66,  67,  69,  69,  69,  68,  69,  64,  65,  64,  63,  64,\n",
       "         66,  66,  66,  65,  65,  74,  74,  73,  73,  73,  75,  76,  74,\n",
       "         75,  75,  70,  71,  70,  70,  70,  72,  72,  71,  72,  55,  55,\n",
       "         55,  54,  54,  56,  56,  57,  55,  56,  51,  52,  52,  50,  51,\n",
       "         53,  53,  53,  52,  52,  61,  61,  60,  60,  60,  62,  63,  62,\n",
       "         62,  62,  58,  58,  57,  57,  57,  59,  60,  59,  59,  59,  93,\n",
       "         93,  92,  92,  94,  94,  95,  93,  94,  90,  89,  90,  89,  89,\n",
       "         91,  92,  91,  90,  91,  99,  99,  99,  98,  98, 101, 101, 100,\n",
       "        100, 100,  96,  96,  95,  96,  95,  97,  98,  97,  97,  97,  80,\n",
       "         80,  79,  80,  82,  82,  82,  81,  81,  77,  77,  77,  76,  77,\n",
       "         78,  79,  79,  77,  78,  87,  87,  87,  86,  86,  88,  88,  87,\n",
       "         87,  87,  83,  84,  82,  82,  83,  85,  85,  84,  84,  84,  16,\n",
       "         17,  16,  16,  16,  18,  18,  17,  18,  13,  13,  13,  12,  13,\n",
       "         15,  15,  15,  14,  15,  23,  23,  23,  22,  22,  25,  25,  24,\n",
       "         24,  24,  20,  20,  19,  19,  19,  21,  22,  20,  21,  21,   3,\n",
       "          4,   3,   3,   3,   5,   6,   5,   5,   1,   0,   1,   0,   0,\n",
       "          2,   2,   2,   1,   2,  10,  10,  10,   9,   9,  12,  12,  12,\n",
       "         11,  11,   7,   7,   6,   6,   6,   8,   9,   8,   8,   8,  42,\n",
       "         42,  41,  42,  41,  43,  44,  43,  43,  43,  39,  39,  38,  38,\n",
       "         40,  40,  40,  39,  40,  48,  48,  49,  47,  48,  50,  50,  50,\n",
       "         49,  49,  45,  45,  44,  44,  44,  47,  47,  46,  46,  46,  29,\n",
       "         30,  28,  29,  29,  31,  31,  30,  30,  30,  26,  26,  25,  26,\n",
       "         28,  27,  28,  27,  27,  35,  35,  36,  35,  35,  37,  38,  37,\n",
       "         36,  37,  32,  33,  33,  31,  32,  34,  34,  33,  33,  33, 169,\n",
       "        170, 168, 168, 169, 170, 171, 170, 170, 170, 166, 166, 165, 165,\n",
       "        165, 167, 168, 167, 167, 175, 175, 176, 174, 175, 177, 177, 177,\n",
       "        176, 177, 172, 173, 172, 171, 172, 174, 174, 173, 173, 173, 156,\n",
       "        157, 156, 155, 156, 158, 158, 157, 157, 157, 153, 154, 152, 153,\n",
       "        153, 155, 155, 154, 154, 163, 163, 163, 162, 162, 164, 164, 165,\n",
       "        163, 164, 159, 160, 160, 158, 159, 161, 161, 161, 160, 160, 194,\n",
       "        195, 194, 194, 194, 196, 197, 195, 195, 196, 191, 192, 191, 191,\n",
       "        191, 193, 193, 192, 192, 192, 201, 201, 200, 201, 202, 202, 203,\n",
       "        201, 202, 198, 198, 198, 197, 197, 199, 200, 199, 198, 199, 182,\n",
       "        182, 181, 181, 181, 183, 184, 183, 182, 183, 178, 179, 178, 178,\n",
       "        178, 180, 181, 179, 180, 180, 188, 188, 187, 188, 190, 190, 190,\n",
       "        189, 189, 185, 185, 185, 184, 185, 186, 187, 187, 185, 186, 118,\n",
       "        119, 118, 117, 118, 120, 120, 119, 119, 119, 115, 116, 114, 114,\n",
       "        115, 116, 117, 116, 116, 116, 124, 125, 124, 124, 126, 126, 126,\n",
       "        125, 126, 121, 121, 122, 120, 121, 123, 123, 123, 122, 123, 106,\n",
       "        106, 106, 104, 105, 107, 107, 106, 106, 106, 102, 103, 102, 101,\n",
       "        102, 104, 104, 103, 103, 103, 112, 112, 111, 111, 111, 113, 114,\n",
       "        113, 113, 109, 109, 109, 108, 108, 110, 110, 111, 109, 110, 144,\n",
       "        144, 144, 143, 143, 145, 146, 145, 144, 145, 140, 141, 140, 139,\n",
       "        140, 142, 143, 141, 141, 141, 150, 150, 149, 150, 149, 151, 152,\n",
       "        151, 151, 151, 147, 147, 146, 146, 148, 148, 149, 147, 148, 131,\n",
       "        131, 131, 130, 131, 133, 133, 133, 131, 132, 128, 128, 127, 127,\n",
       "        127, 129, 130, 129, 128, 129, 137, 138, 136, 137, 137, 139, 139,\n",
       "        138, 138, 138, 134, 134, 133, 134, 136, 136, 136, 135, 135]),\n",
       " array([ 3651,  9402, 12525, 22473,  4490,   460,  8362,  4222, 20328,\n",
       "        18120,  4123,  2188, 17400, 10448,  1962, 10114,  5777,  2505,\n",
       "        10319, 15708, 23579, 19093, 17291, 22698,  4079, 14373,  6160,\n",
       "         4245, 14880, 12651,  3361, 20993,  6748,  5135, 16180,  2828,\n",
       "         5970, 11685,  9881, 10104, 17668, 18333,  1895, 10935,  7493,\n",
       "        15474, 11262,  4606,    21, 22332,  8052,  1698, 16907,  5947,\n",
       "        17151, 12830,  6501, 16750, 23969,  4839,  3226, 23719,  6994,\n",
       "         1603, 11874,  5520,  1161,  8743,  9000,  2095, 17918, 16021,\n",
       "         2593, 13704,  7087,  2885, 10844,  6184,  3974, 14586, 17673,\n",
       "        23996,  8491,  6880, 12402, 15525,   977, 23308, 19218,  2490,\n",
       "        23823, 14420,  3461, 14062, 12183,  2792, 20367, 20906,  4203,\n",
       "          356, 21244,  4539,  8113, 15944, 11422,  9543, 15256, 22914,\n",
       "         8630,   484, 23144,  9135, 22662, 12992,  6352, 16759, 15147,\n",
       "        10506, 21709,   224,  5937,  4057, 12755, 20717, 21406,  5022,\n",
       "         5216,  1734,  9583,  5732, 23399,  9991,  7790, 18097, 11749,\n",
       "         2326,  3458, 11323,  7079,   748, 11058, 13196, 18571, 16959,\n",
       "        12786, 19107,  2192, 12487,  6186,  1829,  9333,   724, 18682,\n",
       "         9604,  7802, 19006, 14358,  7701,  3467, 11026,  6689, 13470,\n",
       "        23971,  2541,  8885,  9098,  7430, 12855, 15698,  1527, 15075,\n",
       "        11045, 18910, 15587,  6185,  4287, 14576, 12774,  3390, 21043,\n",
       "        19688,  2923, 24056, 19897,  3475,  8672, 16528, 12056, 10140,\n",
       "        15814, 14559,  1209, 16760, 14904,   941, 23298, 13570,  6910,\n",
       "        17544, 15627, 19885,  6522,  9664, 15396, 13440, 13337, 21223,\n",
       "        22217,  5604, 21569, 18163,  1439, 22070, 15121, 10171,  8253,\n",
       "        18658, 12326,  2961,  5379, 13209,  9173,  2556, 12753, 20175,\n",
       "         1026, 24008, 19796,  1522,   275, 10885,  4363,     4,  7569,\n",
       "         7783,  1093, 16585,  3252,  1335,  5602, 23521, 19363,  2331,\n",
       "        22509, 20580,  6333,  7926, 15895,  7297,  5708, 11118, 13886,\n",
       "        24207, 22291, 17987,  1319, 22615, 13249,  9419, 19727, 17527,\n",
       "         8460,  1604,  2133, 10004,  6575,  2329, 10489,  6811, 14354,\n",
       "        10275,  8359, 14109, 21626,  8217, 23715, 22143,  7854, 14535,\n",
       "         4826, 22805,  8824,  6868,  3116, 13426, 16764, 22382, 20483,\n",
       "        11600, 19467, 20405,  3714,  4834,   592,  8440,  4578, 22201,\n",
       "        12085, 10167, 20813, 14139,  4869,  6004, 13893,  9839,  3159,\n",
       "        13145, 11853, 17568, 15764, 11564, 17923,   885, 11455,  4814,\n",
       "          173,  8077, 17214, 10590,  1512, 12666, 10766,  6451, 24066,\n",
       "        19979,  2951, 23206, 12429, 22681, 24283,  7595,  8118,  6316,\n",
       "        11722, 14580,   298, 21014, 16656,  3321, 21257, 11973, 10034,\n",
       "        20362, 18138,  9023,  2381, 18371,   936, 22891, 18717,  2313,\n",
       "         7380, 14910, 10723,  9127, 14594,  6405, 17647,  8570,  6923,\n",
       "        17210, 14697,  5293, 23348,  9367,  7488, 19508,  5184,  8617,\n",
       "        14062, 11839, 12150, 19999, 21030,  4283, 21057, 16712,   323,\n",
       "        20730, 13842,  8882,  6988, 17569, 10906,  2433, 18416,  1995,\n",
       "        22326, 15693,  1138,  8662, 14336, 12419,  9175, 14584,  6483,\n",
       "        17081, 10480,  5816, 13626, 14140,  7213, 23628,  9457,  7541,\n",
       "        18965, 12001,  7465, 15313, 11299,  9061, 19472, 21058,  4374,\n",
       "         3048,  1095,  6195,  9364, 19960, 17827, 13469,   134, 18077,\n",
       "         8939, 22492,  7938,  6022, 21624, 14980, 15211, 21531, 19578,\n",
       "        15691, 23576, 12562, 20529, 16323, 14734, 20157, 21249, 14286,\n",
       "         5535,  3634, 14040,  2690, 17884, 11571, 21822, 18378, 16156,\n",
       "         2189,  5436, 10841,  8642,  3783, 11884, 12574, 23812, 21599,\n",
       "        17450,   934, 21331, 14083,   552, 23461,  9198,  1040, 18721,\n",
       "        19010,  2619, 22851, 15857,  1556, 18253, 23684,  8849, 18592,\n",
       "        24015,  7312, 17585, 10615,  6272, 14449,  5852, 23578, 15420,\n",
       "         1170, 24135, 19407, 12138,  7984, 16137, 11894,  7787, 19028,\n",
       "        19718,  3259,  3454,  1270,  6677,  9922, 20516,  9528,  6087,\n",
       "        16337, 10008,   640, 22668,  8495,  6579, 22421, 15460,   747,\n",
       "         6154,  4582,   389,  8351, 13120, 21007, 17120, 15165, 21487,\n",
       "        12933,  6284, 21888, 19972,  5418,  3186, 18625, 11987, 23231,\n",
       "        18873, 17916,  3932,  7103, 12203, 10249, 10748, 18634, 20238,\n",
       "         6065, 19612, 15584, 23448, 18907, 11946,  7587,  5686, 16094,\n",
       "         7928,   987, 10306, 18135, 13453,  6857, 17452,   498,  6068,\n",
       "         2664,   763,  6429,  5171, 15193,  8546,  4398, 12461, 12689,\n",
       "         4217, 22141,  8141,  6243, 24030, 17122, 12988, 21157, 16822,\n",
       "        17912,  1166,  2177, 10048,  1362, 23928,  4758,  8231, 18522,\n",
       "        14713, 12798, 23430, 16791,  7502, 13763, 24090, 22479, 13354,\n",
       "        24571,  7553, 13267, 11466,  7266, 14846, 11121, 19236, 15042,\n",
       "        11637, 19486, 19799, 13154,  4104,  1882, 12132,  5302, 20511,\n",
       "        17230,   619, 20837, 18953,  4669,  7443, 12854, 11279,  2678,\n",
       "        10639, 12243, 22570, 20631, 16235, 23778, 19622, 12964, 17196,\n",
       "        15280,  1944, 17447, 10752, 11001, 18613, 14236,  7648, 18246,\n",
       "        17027, 23348, 19116, 17505, 22949,  5586, 15988,  9356,  5342,\n",
       "        13190, 12296,  2938, 21110,  6863,  5055,   140, 17777, 13904,\n",
       "        21714, 18271,  9599, 17770, 18510,  1647,  1764, 24437,  5525,\n",
       "         8663, 19891, 24239, 22534,  8455,  1840, 16724, 14459,   459,\n",
       "        23137, 14997,   841, 24021,  5201,  3296, 23288,  6583, 12113,\n",
       "        19979, 15653, 12401, 20303,  7931,   954, 16119, 14204,   261,\n",
       "        22602, 13324, 10034, 17921, 13868,  2798, 12780, 15950, 21662,\n",
       "        19860, 20056,  1841,  4970, 15527, 22085, 17446,   734, 21329,\n",
       "        14575,  9941, 21168, 19232, 10419,  3492, 19174,  2500, 22779,\n",
       "        16444,  2204,  8193, 16004, 12117, 10238, 15339, 21143,  6865,\n",
       "          531, 20746,  7351,  5136, 20650, 14018, 24421, 22199,  8643,\n",
       "         2022, 22387,  4113,  2217,  2766, 10675, 11401, 18963,  3474,\n",
       "         1865,  7234,  3945, 21606, 17243, 15440,  1156, 18813,  9419,\n",
       "        23210,  8922,  5517, 23464,  9289, 17117, 22548, 20341, 16105,\n",
       "        24258, 24282, 10910,  4394,    38,  8210,  8420,  1128, 16615,\n",
       "        15021,   754, 12792,  5942,  1752,  9943,  5586,  2995, 13282,\n",
       "        16758, 22164, 20362,  5692, 11140, 14571,   244, 22277, 17944,\n",
       "         1536, 22036, 15071,  2510, 12817, 11151,  2092, 19418, 19654,\n",
       "         3142, 23571, 16928,  3582,  6875, 14991, 10784,  8601, 14012,\n",
       "        21652,  7677,  1077, 22210,  7884, 21716, 12352,  5400, 15811,\n",
       "        13892,  9542,  2599, 23854,  4685,  3097, 12148, 20104, 20487,\n",
       "         3784,  4308,  2374,  8676,  4503, 22439,  9001,  7146, 17146,\n",
       "        10527,  1435, 23728, 10362,  6039, 24287, 10113, 20493,  1057,\n",
       "        23694, 19775,  3085,  8694, 19501, 12888,  8832, 16642,  7738,\n",
       "          794, 16397, 14801,   535, 21313, 14354, 10490, 18454, 14090,\n",
       "        20452,  6147,  9555, 14999, 16125, 14321, 19748, 23193,  8867,\n",
       "        22089, 17740,  1138, 21786, 14880, 11096, 21383, 19808, 10776,\n",
       "         3874,  1816,  9667,  5572, 23524, 10169, 15375, 23241, 19363,\n",
       "        17406, 22505, 21246,  7078,   721, 20974,  7550,  5351, 20866,\n",
       "        14220, 24426, 22437,  2042, 19944, 15736, 22079, 20274, 20508,\n",
       "         4125,  4764, 12309,  3675,  1203,  7581, 10739, 21944, 17252,\n",
       "        15675,  1395, 19419,  9721,   982, 11538,  9622,  1478, 11788,\n",
       "        19515,   556, 23216, 18758,  2030, 23169,  6440,  3201, 23422,\n",
       "         6808,  7307,   387, 15576, 13623, 24216,  6203, 22313, 18222,\n",
       "         1495, 22019, 19826,  5178,  8325, 14053, 12158,  4081, 10001,\n",
       "        13135, 23767, 21520, 16820,    91, 20818, 13856,  8958, 20163,\n",
       "        18252,  9519,  2570,  2442, 10293,  6208, 24167, 10795,  7161,\n",
       "        15340, 11164,  8947, 14487, 21966,  7983,  1368, 22545,  8259,\n",
       "        13583,  4166, 21821,  7591,  5728,  1412, 19011, 15692, 21140,\n",
       "        19430, 12494, 20381, 20704,  3996,  3072,  1177,  7482,  4791,\n",
       "        20319]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unravel_index(foo[0], shape=(d_sae, d_sae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([244, 244, 243, 243, 252, 252, 252, 251, 251, 253, 254, 254, 252,\n",
       "       253, 249, 249, 249, 248, 248, 250, 250, 249, 249, 249, 233, 233,\n",
       "       232, 232, 232, 234, 235, 233, 234, 234, 229, 230, 229, 229, 229,\n",
       "       231, 231, 230, 231, 239, 239, 239, 238, 239, 241, 240, 241, 240,\n",
       "       240, 236, 236, 236, 235, 235, 237, 238, 238, 236, 237, 373, 373,\n",
       "       372, 372, 372, 374, 375, 373, 373, 374, 369, 370, 369, 369, 369,\n",
       "       371, 371, 370, 370, 379, 379, 379, 378, 379, 380, 380, 381, 379,\n",
       "       380, 376, 376, 376, 375, 375, 377, 378, 378, 376, 377, 360, 360,\n",
       "       359, 359, 359, 361, 362, 361, 360, 361, 356, 357, 356, 356, 356,\n",
       "       358, 358, 358, 358, 358, 366, 366, 365, 366, 368, 368, 368, 367,\n",
       "       367, 363, 363, 363, 362, 363, 365, 365, 365, 364, 364, 398, 398,\n",
       "       398, 397, 397, 400, 400, 399, 399, 399, 395, 395, 394, 394, 394,\n",
       "       396, 397, 396, 396, 396, 404, 404, 404, 404, 406, 406, 406, 405,\n",
       "       406, 401, 401, 401, 400, 401, 403, 403, 403, 402, 402, 385, 386,\n",
       "       385, 384, 385, 387, 387, 386, 386, 386, 382, 383, 381, 381, 382,\n",
       "       383, 384, 383, 383, 383, 391, 392, 391, 391, 391, 393, 393, 392,\n",
       "       393, 388, 388, 389, 387, 388, 390, 390, 390, 389, 390, 322, 322,\n",
       "       322, 321, 321, 323, 324, 323, 322, 323, 319, 319, 318, 318, 318,\n",
       "       320, 321, 319, 320, 320, 328, 328, 327, 328, 327, 329, 330, 329,\n",
       "       329, 325, 325, 325, 324, 324, 326, 326, 327, 325, 326, 309, 309,\n",
       "       309, 308, 309, 311, 311, 311, 310, 310, 306, 306, 305, 305, 305,\n",
       "       307, 308, 306, 306, 307, 315, 316, 314, 315, 315, 317, 317, 316,\n",
       "       316, 316, 312, 312, 311, 312, 314, 314, 314, 313, 313, 347, 347,\n",
       "       347, 346, 347, 349, 349, 349, 348, 348, 344, 344, 344, 343, 343,\n",
       "       346, 346, 345, 345, 345, 353, 354, 353, 353, 353, 355, 355, 354,\n",
       "       355, 354, 350, 350, 349, 350, 352, 352, 352, 351, 352, 334, 334,\n",
       "       335, 333, 334, 336, 336, 336, 335, 336, 331, 332, 331, 330, 331,\n",
       "       333, 333, 332, 332, 332, 341, 341, 340, 340, 340, 342, 343, 341,\n",
       "       342, 342, 337, 338, 337, 337, 337, 339, 339, 338, 339,  67,  67,\n",
       "        68,  66,  67,  69,  69,  69,  68,  69,  64,  65,  64,  63,  64,\n",
       "        66,  66,  66,  65,  65,  74,  74,  73,  73,  73,  75,  76,  74,\n",
       "        75,  75,  70,  71,  70,  70,  70,  72,  72,  71,  72,  55,  55,\n",
       "        55,  54,  54,  56,  56,  57,  55,  56,  51,  52,  52,  50,  51,\n",
       "        53,  53,  53,  52,  52,  61,  61,  60,  60,  60,  62,  63,  62,\n",
       "        62,  62,  58,  58,  57,  57,  57,  59,  60,  59,  59,  59,  93,\n",
       "        93,  92,  92,  94,  94,  95,  93,  94,  90,  89,  90,  89,  89,\n",
       "        91,  92,  91,  90,  91,  99,  99,  99,  98,  98, 101, 101, 100,\n",
       "       100, 100,  96,  96,  95,  96,  95,  97,  98,  97,  97,  97,  80,\n",
       "        80,  79,  80,  82,  82,  82,  81,  81,  77,  77,  77,  76,  77,\n",
       "        78,  79,  79,  77,  78,  87,  87,  87,  86,  86,  88,  88,  87,\n",
       "        87,  87,  83,  84,  82,  82,  83,  85,  85,  84,  84,  84,  16,\n",
       "        17,  16,  16,  16,  18,  18,  17,  18,  13,  13,  13,  12,  13,\n",
       "        15,  15,  15,  14,  15,  23,  23,  23,  22,  22,  25,  25,  24,\n",
       "        24,  24,  20,  20,  19,  19,  19,  21,  22,  20,  21,  21,   3,\n",
       "         4,   3,   3,   3,   5,   6,   5,   5,   1,   0,   1,   0,   0,\n",
       "         2,   2,   2,   1,   2,  10,  10,  10,   9,   9,  12,  12,  12,\n",
       "        11,  11,   7,   7,   6,   6,   6,   8,   9,   8,   8,   8,  42,\n",
       "        42,  41,  42,  41,  43,  44,  43,  43,  43,  39,  39,  38,  38,\n",
       "        40,  40,  40,  39,  40,  48,  48,  49,  47,  48,  50,  50,  50,\n",
       "        49,  49,  45,  45,  44,  44,  44,  47,  47,  46,  46,  46,  29,\n",
       "        30,  28,  29,  29,  31,  31,  30,  30,  30,  26,  26,  25,  26,\n",
       "        28,  27,  28,  27,  27,  35,  35,  36,  35,  35,  37,  38,  37,\n",
       "        36,  37,  32,  33,  33,  31,  32,  34,  34,  33,  33,  33, 169,\n",
       "       170, 168, 168, 169, 170, 171, 170, 170, 170, 166, 166, 165, 165,\n",
       "       165, 167, 168, 167, 167, 175, 175, 176, 174, 175, 177, 177, 177,\n",
       "       176, 177, 172, 173, 172, 171, 172, 174, 174, 173, 173, 173, 156,\n",
       "       157, 156, 155, 156, 158, 158, 157, 157, 157, 153, 154, 152, 153,\n",
       "       153, 155, 155, 154, 154, 163, 163, 163, 162, 162, 164, 164, 165,\n",
       "       163, 164, 159, 160, 160, 158, 159, 161, 161, 161, 160, 160, 194,\n",
       "       195, 194, 194, 194, 196, 197, 195, 195, 196, 191, 192, 191, 191,\n",
       "       191, 193, 193, 192, 192, 192, 201, 201, 200, 201, 202, 202, 203,\n",
       "       201, 202, 198, 198, 198, 197, 197, 199, 200, 199, 198, 199, 182,\n",
       "       182, 181, 181, 181, 183, 184, 183, 182, 183, 178, 179, 178, 178,\n",
       "       178, 180, 181, 179, 180, 180, 188, 188, 187, 188, 190, 190, 190,\n",
       "       189, 189, 185, 185, 185, 184, 185, 186, 187, 187, 185, 186, 118,\n",
       "       119, 118, 117, 118, 120, 120, 119, 119, 119, 115, 116, 114, 114,\n",
       "       115, 116, 117, 116, 116, 116, 124, 125, 124, 124, 126, 126, 126,\n",
       "       125, 126, 121, 121, 122, 120, 121, 123, 123, 123, 122, 123, 106,\n",
       "       106, 106, 104, 105, 107, 107, 106, 106, 106, 102, 103, 102, 101,\n",
       "       102, 104, 104, 103, 103, 103, 112, 112, 111, 111, 111, 113, 114,\n",
       "       113, 113, 109, 109, 109, 108, 108, 110, 110, 111, 109, 110, 144,\n",
       "       144, 144, 143, 143, 145, 146, 145, 144, 145, 140, 141, 140, 139,\n",
       "       140, 142, 143, 141, 141, 141, 150, 150, 149, 150, 149, 151, 152,\n",
       "       151, 151, 151, 147, 147, 146, 146, 148, 148, 149, 147, 148, 131,\n",
       "       131, 131, 130, 131, 133, 133, 133, 131, 132, 128, 128, 127, 127,\n",
       "       127, 129, 130, 129, 128, 129, 137, 138, 136, 137, 137, 139, 139,\n",
       "       138, 138, 138, 134, 134, 133, 134, 136, 136, 136, 135, 135])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unravel_index(foo[0], shape=(d_sae, d_sae))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 229, 230, 231, 232,\n",
       "        233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 248, 249,\n",
       "        250, 251, 252, 253, 254, 305, 306, 307, 308, 309, 310, 311, 312,\n",
       "        313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
       "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
       "        339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
       "        352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
       "        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
       "        391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
       "        404, 405, 406]),\n",
       " array([3, 3, 4, 4, 1, 3, 4, 2, 4, 3, 3, 2, 4, 4, 1, 4, 4, 2, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 2, 5, 2, 4, 2, 3, 3, 3, 4, 2, 3, 4,\n",
       "        4, 2, 3, 3, 3, 3, 4, 2, 4, 3, 2, 4, 3, 4, 2, 4, 4, 2, 4, 2, 3, 3,\n",
       "        4, 3, 2, 4, 4, 2, 3, 3, 3, 3, 2, 5, 2, 3, 3, 2, 5, 2, 4, 2, 2, 6,\n",
       "        2, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 4, 3, 1, 6, 2, 2, 4,\n",
       "        3, 4, 2, 3, 3, 2, 5, 2, 3, 4, 3, 3, 2, 4, 3, 2, 4, 3, 3, 3, 2, 5,\n",
       "        1, 4, 3, 2, 4, 3, 4, 3, 3, 4, 1, 3, 4, 3, 3, 3, 3, 3, 3, 4, 2, 3,\n",
       "        3, 3, 3, 4, 3, 2, 4, 3, 2, 4, 3, 4, 2, 3, 3, 2, 5, 2, 3, 4, 3, 3,\n",
       "        2, 4, 4, 2, 3, 4, 3, 3, 2, 5, 2, 3, 3, 2, 3, 4, 4, 2, 4, 3, 2, 3,\n",
       "        4, 3, 2, 4, 3, 1, 4, 2, 3, 3, 3, 3, 3, 4, 2, 3, 4, 3, 2, 2, 2, 2,\n",
       "        6, 2, 2, 4, 2, 2, 3, 4, 2, 2, 4, 2, 4, 3, 2, 4, 3, 4, 2, 3, 3, 3,\n",
       "        3, 4, 3, 3, 4, 3, 3, 3, 3, 2, 3, 4, 3, 3, 2, 4, 4, 2, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 4, 2, 4, 3, 1, 4, 4, 3, 3, 4, 1, 5, 3, 3, 3, 2, 4, 2,\n",
       "        4, 3, 2, 3, 4, 3, 2, 3, 4, 2, 3, 4, 2, 3, 5, 3, 3, 2, 5, 2, 3, 4,\n",
       "        3, 3, 2, 4, 4, 2, 3, 3, 2, 4, 3, 3, 3, 3, 4, 2, 3, 4, 1, 4]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.unravel_index(foo[0], shape=(d_sae, d_sae))[0], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unravel_index(foo[0], shape=(d_sae, d_sae))[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20319"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unravel_index(foo[0], shape=(d_sae, d_sae))[1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_scores[0][135][20319]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 24576, 24576)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 135)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.unravel_index(foo[0], shape=(d_sae, d_sae))[0][0], np.unravel_index(foo[0], shape=(d_sae, d_sae))[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6000195, 6005946, 5984493, ..., 3349818, 3322551, 3338079],\n",
       "       [6000378, 6005899, 5984454, ..., 3349807, 3322422, 3335716],\n",
       "       [6000294, 6005739, 5983985, ..., 3348752, 3322192, 3336923],\n",
       "       ...,\n",
       "       [5999275, 6005011, 5983553, ..., 3352331, 3322375, 3331775],\n",
       "       [5999058, 6004809, 5983354, ..., 3352306, 3322241, 3332726],\n",
       "       [5999338, 6004861, 5983709, ..., 3352456, 3321478, 3331805]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_first_idx, first_layer_second_idx = np.unravel_index(foo[0], shape=(d_sae, d_sae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([244, 244, 243, 243, 252, 252, 252, 251, 251, 253, 254, 254, 252,\n",
       "       253, 249, 249, 249, 248, 248, 250, 250, 249, 249, 249, 233, 233,\n",
       "       232, 232, 232, 234, 235, 233, 234, 234, 229, 230, 229, 229, 229,\n",
       "       231, 231, 230, 231, 239, 239, 239, 238, 239, 241, 240, 241, 240,\n",
       "       240, 236, 236, 236, 235, 235, 237, 238, 238, 236, 237, 373, 373,\n",
       "       372, 372, 372, 374, 375, 373, 373, 374, 369, 370, 369, 369, 369,\n",
       "       371, 371, 370, 370, 379, 379, 379, 378, 379, 380, 380, 381, 379,\n",
       "       380, 376, 376, 376, 375, 375, 377, 378, 378, 376, 377, 360, 360,\n",
       "       359, 359, 359, 361, 362, 361, 360, 361, 356, 357, 356, 356, 356,\n",
       "       358, 358, 358, 358, 358, 366, 366, 365, 366, 368, 368, 368, 367,\n",
       "       367, 363, 363, 363, 362, 363, 365, 365, 365, 364, 364, 398, 398,\n",
       "       398, 397, 397, 400, 400, 399, 399, 399, 395, 395, 394, 394, 394,\n",
       "       396, 397, 396, 396, 396, 404, 404, 404, 404, 406, 406, 406, 405,\n",
       "       406, 401, 401, 401, 400, 401, 403, 403, 403, 402, 402, 385, 386,\n",
       "       385, 384, 385, 387, 387, 386, 386, 386, 382, 383, 381, 381, 382,\n",
       "       383, 384, 383, 383, 383, 391, 392, 391, 391, 391, 393, 393, 392,\n",
       "       393, 388, 388, 389, 387, 388, 390, 390, 390, 389, 390, 322, 322,\n",
       "       322, 321, 321, 323, 324, 323, 322, 323, 319, 319, 318, 318, 318,\n",
       "       320, 321, 319, 320, 320, 328, 328, 327, 328, 327, 329, 330, 329,\n",
       "       329, 325, 325, 325, 324, 324, 326, 326, 327, 325, 326, 309, 309,\n",
       "       309, 308, 309, 311, 311, 311, 310, 310, 306, 306, 305, 305, 305,\n",
       "       307, 308, 306, 306, 307, 315, 316, 314, 315, 315, 317, 317, 316,\n",
       "       316, 316, 312, 312, 311, 312, 314, 314, 314, 313, 313, 347, 347,\n",
       "       347, 346, 347, 349, 349, 349, 348, 348, 344, 344, 344, 343, 343,\n",
       "       346, 346, 345, 345, 345, 353, 354, 353, 353, 353, 355, 355, 354,\n",
       "       355, 354, 350, 350, 349, 350, 352, 352, 352, 351, 352, 334, 334,\n",
       "       335, 333, 334, 336, 336, 336, 335, 336, 331, 332, 331, 330, 331,\n",
       "       333, 333, 332, 332, 332, 341, 341, 340, 340, 340, 342, 343, 341,\n",
       "       342, 342, 337, 338, 337, 337, 337, 339, 339, 338, 339,  67,  67,\n",
       "        68,  66,  67,  69,  69,  69,  68,  69,  64,  65,  64,  63,  64,\n",
       "        66,  66,  66,  65,  65,  74,  74,  73,  73,  73,  75,  76,  74,\n",
       "        75,  75,  70,  71,  70,  70,  70,  72,  72,  71,  72,  55,  55,\n",
       "        55,  54,  54,  56,  56,  57,  55,  56,  51,  52,  52,  50,  51,\n",
       "        53,  53,  53,  52,  52,  61,  61,  60,  60,  60,  62,  63,  62,\n",
       "        62,  62,  58,  58,  57,  57,  57,  59,  60,  59,  59,  59,  93,\n",
       "        93,  92,  92,  94,  94,  95,  93,  94,  90,  89,  90,  89,  89,\n",
       "        91,  92,  91,  90,  91,  99,  99,  99,  98,  98, 101, 101, 100,\n",
       "       100, 100,  96,  96,  95,  96,  95,  97,  98,  97,  97,  97,  80,\n",
       "        80,  79,  80,  82,  82,  82,  81,  81,  77,  77,  77,  76,  77,\n",
       "        78,  79,  79,  77,  78,  87,  87,  87,  86,  86,  88,  88,  87,\n",
       "        87,  87,  83,  84,  82,  82,  83,  85,  85,  84,  84,  84,  16,\n",
       "        17,  16,  16,  16,  18,  18,  17,  18,  13,  13,  13,  12,  13,\n",
       "        15,  15,  15,  14,  15,  23,  23,  23,  22,  22,  25,  25,  24,\n",
       "        24,  24,  20,  20,  19,  19,  19,  21,  22,  20,  21,  21,   3,\n",
       "         4,   3,   3,   3,   5,   6,   5,   5,   1,   0,   1,   0,   0,\n",
       "         2,   2,   2,   1,   2,  10,  10,  10,   9,   9,  12,  12,  12,\n",
       "        11,  11,   7,   7,   6,   6,   6,   8,   9,   8,   8,   8,  42,\n",
       "        42,  41,  42,  41,  43,  44,  43,  43,  43,  39,  39,  38,  38,\n",
       "        40,  40,  40,  39,  40,  48,  48,  49,  47,  48,  50,  50,  50,\n",
       "        49,  49,  45,  45,  44,  44,  44,  47,  47,  46,  46,  46,  29,\n",
       "        30,  28,  29,  29,  31,  31,  30,  30,  30,  26,  26,  25,  26,\n",
       "        28,  27,  28,  27,  27,  35,  35,  36,  35,  35,  37,  38,  37,\n",
       "        36,  37,  32,  33,  33,  31,  32,  34,  34,  33,  33,  33, 169,\n",
       "       170, 168, 168, 169, 170, 171, 170, 170, 170, 166, 166, 165, 165,\n",
       "       165, 167, 168, 167, 167, 175, 175, 176, 174, 175, 177, 177, 177,\n",
       "       176, 177, 172, 173, 172, 171, 172, 174, 174, 173, 173, 173, 156,\n",
       "       157, 156, 155, 156, 158, 158, 157, 157, 157, 153, 154, 152, 153,\n",
       "       153, 155, 155, 154, 154, 163, 163, 163, 162, 162, 164, 164, 165,\n",
       "       163, 164, 159, 160, 160, 158, 159, 161, 161, 161, 160, 160, 194,\n",
       "       195, 194, 194, 194, 196, 197, 195, 195, 196, 191, 192, 191, 191,\n",
       "       191, 193, 193, 192, 192, 192, 201, 201, 200, 201, 202, 202, 203,\n",
       "       201, 202, 198, 198, 198, 197, 197, 199, 200, 199, 198, 199, 182,\n",
       "       182, 181, 181, 181, 183, 184, 183, 182, 183, 178, 179, 178, 178,\n",
       "       178, 180, 181, 179, 180, 180, 188, 188, 187, 188, 190, 190, 190,\n",
       "       189, 189, 185, 185, 185, 184, 185, 186, 187, 187, 185, 186, 118,\n",
       "       119, 118, 117, 118, 120, 120, 119, 119, 119, 115, 116, 114, 114,\n",
       "       115, 116, 117, 116, 116, 116, 124, 125, 124, 124, 126, 126, 126,\n",
       "       125, 126, 121, 121, 122, 120, 121, 123, 123, 123, 122, 123, 106,\n",
       "       106, 106, 104, 105, 107, 107, 106, 106, 106, 102, 103, 102, 101,\n",
       "       102, 104, 104, 103, 103, 103, 112, 112, 111, 111, 111, 113, 114,\n",
       "       113, 113, 109, 109, 109, 108, 108, 110, 110, 111, 109, 110, 144,\n",
       "       144, 144, 143, 143, 145, 146, 145, 144, 145, 140, 141, 140, 139,\n",
       "       140, 142, 143, 141, 141, 141, 150, 150, 149, 150, 149, 151, 152,\n",
       "       151, 151, 151, 147, 147, 146, 146, 148, 148, 149, 147, 148, 131,\n",
       "       131, 131, 130, 131, 133, 133, 133, 131, 132, 128, 128, 127, 127,\n",
       "       127, 129, 130, 129, 128, 129, 137, 138, 136, 137, 137, 139, 139,\n",
       "       138, 138, 138, 134, 134, 133, 134, 136, 136, 136, 135, 135])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer_first_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3651 is out of bounds for axis 0 with size 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m interaction_scores[\u001b[39m0\u001b[39;49m][first_layer_first_idx][first_layer_second_idx]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3651 is out of bounds for axis 0 with size 1000"
     ]
    }
   ],
   "source": [
    "interaction_scores[0][first_layer_first_idx][first_layer_second_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction_scores[0,first_layer_first_idx,first_layer_second_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'count_nonzero'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m interaction_scores[\u001b[39m0\u001b[39;49m,first_layer_first_idx,first_layer_second_idx]\u001b[39m.\u001b[39;49mcount_nonzero()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'count_nonzero'"
     ]
    }
   ],
   "source": [
    "interaction_scores[0,first_layer_first_idx,first_layer_second_idx].count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(interaction_scores[0,first_layer_first_idx,first_layer_second_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flattened_per_layer_scores \u001b[39m=\u001b[39m interaction_scores\u001b[39m.\u001b[39mreshape(num_layers, d_sae\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      2\u001b[0m flattened_per_layer_scores \u001b[39m=\u001b[39m flattened_per_layer_scores[:,:\u001b[39m10000000\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_layers' is not defined"
     ]
    }
   ],
   "source": [
    "flattened_per_layer_scores = interaction_scores.reshape(num_layers, d_sae**2)\n",
    "flattened_per_layer_scores = flattened_per_layer_scores[:,:10000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers, d_sae, _ = interaction_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_per_layer_scores = interaction_scores.reshape(num_layers, d_sae**2)\n",
    "flattened_per_layer_scores = flattened_per_layer_scores[:,:10000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 10000000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_per_layer_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47850"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(flattened_per_layer_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
